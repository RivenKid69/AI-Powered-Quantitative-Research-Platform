"""
Comprehensive test for VGS + PBT State Mismatch Problem

This test verifies that VGS state is correctly handled during PBT exploitation.
The problem: When PBT exploits (copies checkpoint from better member), the VGS
state may not be synchronized, leading to mismatch between policy weights and
VGS gradient statistics.

Test strategy:
1. Create two models with different VGS statistics
2. Simulate PBT exploitation (member A copies from member B)
3. Verify VGS state is correctly synchronized or reset
"""

import pytest
import torch
import tempfile
import os
import numpy as np
from pathlib import Path
from typing import Dict, Any

# Import required components
try:
    from distributional_ppo import DistributionalPPO
    from variance_gradient_scaler import VarianceGradientScaler
    from adversarial.pbt_scheduler import PBTScheduler, PBTConfig, HyperparamConfig, PopulationMember
    from custom_policy_patch1 import CustomActorCriticPolicy
    import gymnasium as gym
    from stable_baselines3.common.vec_env import DummyVecEnv
except ImportError as e:
    pytest.skip(f"Required imports not available: {e}", allow_module_level=True)


def make_test_env(seed=None):
    """Create a Pendulum environment for testing (continuous action space)."""
    def _make():
        env = gym.make("Pendulum-v1")
        if seed is not None:
            env.reset(seed=seed)
        return env
    return DummyVecEnv([_make])


def create_test_model(learning_rate=1e-4, use_vgs=True, seed=None):
    """Create a test model with VGS configuration."""
    env = make_test_env(seed=seed)

    model = DistributionalPPO(
        CustomActorCriticPolicy,
        env,
        learning_rate=learning_rate,
        n_steps=32,
        batch_size=32,
        n_epochs=2,
        verbose=0,
        # VGS configuration
        variance_gradient_scaling=use_vgs,
        vgs_beta=0.99,
        vgs_alpha=0.1,
        vgs_warmup_steps=10,  # Low for testing
        seed=seed,
    )

    return model, env


def get_vgs_state(model: DistributionalPPO) -> Dict[str, Any]:
    """Extract VGS state from model."""
    if model._variance_gradient_scaler is None:
        return {"enabled": False, "state": None}

    state = model._variance_gradient_scaler.state_dict()
    return {
        "enabled": True,
        "step_count": state.get("step_count", 0),
        "grad_mean_ema": state.get("grad_mean_ema"),
        "grad_var_ema": state.get("grad_var_ema"),
        "grad_norm_ema": state.get("grad_norm_ema"),
        "grad_max_ema": state.get("grad_max_ema"),
    }


def print_vgs_comparison(name_a: str, state_a: Dict, name_b: str, state_b: Dict):
    """Print VGS state comparison."""
    print(f"\nVGS State Comparison:")
    grad_var_a_str = f"{state_a['grad_var_ema']:.6e}" if state_a['grad_var_ema'] is not None else 'None'
    grad_var_b_str = f"{state_b['grad_var_ema']:.6e}" if state_b['grad_var_ema'] is not None else 'None'
    print(f"  {name_a}: step_count={state_a['step_count']}, grad_var_ema={grad_var_a_str}")
    print(f"  {name_b}: step_count={state_b['step_count']}, grad_var_ema={grad_var_b_str}")


class TestVGS_PBT_StateMismatch:
    """Test suite for VGS + PBT state synchronization."""

    def test_vgs_state_after_model_load(self):
        """
        Test 1: Verify VGS state is preserved after model.save() / model.load().

        This is the BASELINE test - if this passes, the serialization mechanism
        works correctly through DistributionalPPO.save/load.
        """
        print("\n" + "=" * 70)
        print("TEST 1: VGS State Preservation via DistributionalPPO.save/load")
        print("=" * 70)

        # Create and train model
        model_original, env = create_test_model(learning_rate=1e-4, use_vgs=True, seed=42)

        print("\n1. Training model (100 timesteps)...")
        model_original.learn(total_timesteps=100, progress_bar=False)

        vgs_before = get_vgs_state(model_original)
        print(f"\n2. VGS state before save:")
        print(f"   step_count: {vgs_before['step_count']}")
        grad_var_str = f"{vgs_before['grad_var_ema']:.6e}" if vgs_before['grad_var_ema'] is not None else 'None'
        print(f"   grad_var_ema: {grad_var_str}")

        # Save and load
        with tempfile.TemporaryDirectory() as tmpdir:
            save_path = Path(tmpdir) / "model.zip"

            print(f"\n3. Saving model to {save_path}...")
            model_original.save(save_path)

            print(f"4. Loading model from {save_path}...")
            model_loaded = DistributionalPPO.load(save_path, env=env)

            vgs_after = get_vgs_state(model_loaded)
            print(f"\n5. VGS state after load:")
            print(f"   step_count: {vgs_after['step_count']}")
            grad_var_str = f"{vgs_after['grad_var_ema']:.6e}" if vgs_after['grad_var_ema'] is not None else 'None'
            print(f"   grad_var_ema: {grad_var_str}")

            # Verify state is preserved
            print("\n6. Verification:")
            assert vgs_after['enabled'], "VGS should be enabled after load"
            assert vgs_after['step_count'] == vgs_before['step_count'], \
                f"step_count mismatch: {vgs_after['step_count']} != {vgs_before['step_count']}"

            if vgs_before['grad_var_ema'] is not None and vgs_after['grad_var_ema'] is not None:
                var_diff = abs(vgs_after['grad_var_ema'] - vgs_before['grad_var_ema'])
                tolerance = 1e-8
                assert var_diff < tolerance, \
                    f"grad_var_ema mismatch: diff={var_diff:.2e} > tolerance={tolerance:.2e}"
                print(f"   [OK] VGS state preserved (diff={var_diff:.2e})")
            else:
                print("   [WARN] VGS grad_var_ema is None (not enough training)")

            # Test continued training
            print("\n7. Testing continued training...")
            model_loaded.learn(total_timesteps=50, progress_bar=False)
            print("   [OK] Training continues successfully")

            print("\n" + "=" * 70)
            print("[PASS] TEST 1 PASSED: VGS state correctly preserved via save/load")
            print("=" * 70)

    def test_vgs_state_after_pbt_style_checkpoint_load(self):
        """
        Test 2: Verify VGS state when using DistributionalPPO.load() for exploitation.

        This tests the CORRECT way: Using DistributionalPPO.load() which should
        restore VGS state properly.
        """
        print("\n" + "=" * 70)
        print("TEST 2: VGS State After model.load() (Correct Approach)")
        print("=" * 70)

        # Create two models with different training histories
        model_a, env_a = create_test_model(learning_rate=1e-4, use_vgs=True, seed=42)
        model_b, env_b = create_test_model(learning_rate=5e-4, use_vgs=True, seed=123)

        print("\n1. Training Member A (50 timesteps, lr=1e-4)...")
        model_a.learn(total_timesteps=50, progress_bar=False)

        print("2. Training Member B (150 timesteps, lr=5e-4)...")
        model_b.learn(total_timesteps=150, progress_bar=False)

        # Record VGS states
        vgs_a_before = get_vgs_state(model_a)
        vgs_b = get_vgs_state(model_b)

        print_vgs_comparison("Member A (before exploit)", vgs_a_before,
                           "Member B (source)", vgs_b)

        # Save full checkpoint
        with tempfile.TemporaryDirectory() as tmpdir:
            checkpoint_b_path = Path(tmpdir) / "member_b.zip"

            print(f"\n3. Saving Member B checkpoint...")
            model_b.save(checkpoint_b_path)

            # Load using DistributionalPPO.load() (correct approach)
            print("\n4. Loading Member B checkpoint into Member A using model.load()...")
            model_a_loaded = DistributionalPPO.load(checkpoint_b_path, env=env_a)

            vgs_a_after = get_vgs_state(model_a_loaded)

            print_vgs_comparison("Member A (after load)", vgs_a_after,
                               "Member B (expected)", vgs_b)

            # Verification
            print("\n5. Verification:")
            step_match = (vgs_a_after['step_count'] == vgs_b['step_count'])

            if step_match:
                print(f"   [OK] VGS step_count matches ({vgs_a_after['step_count']} == {vgs_b['step_count']})")
            else:
                print(f"   [FAIL] VGS step_count mismatch: {vgs_a_after['step_count']} != {vgs_b['step_count']}")

            # Check grad_var_ema
            var_match = True
            if vgs_a_after['grad_var_ema'] is not None and vgs_b['grad_var_ema'] is not None:
                var_diff = abs(vgs_a_after['grad_var_ema'] - vgs_b['grad_var_ema'])
                tolerance = 1e-8
                var_match = (var_diff < tolerance)

                if var_match:
                    print(f"   [OK] VGS grad_var_ema matches (diff={var_diff:.2e})")
                else:
                    print(f"   [FAIL] VGS grad_var_ema mismatch (diff={var_diff:.2e})")
            else:
                print("   [WARN]  VGS grad_var_ema is None")

            # Test training
            print("\n6. Testing continued training...")
            try:
                model_a_loaded.learn(total_timesteps=50, progress_bar=False)
                print("   [OK] Training continues successfully")
                training_ok = True
            except Exception as e:
                print(f"   [FAIL] Training failed: {e}")
                training_ok = False

            # Final verdict
            print("\n" + "=" * 70)
            if step_match and var_match and training_ok:
                print("[PASS] TEST 2 PASSED: VGS state correctly synchronized via model.load()")
            else:
                print("[FAIL] TEST 2 FAILED: VGS state mismatch detected!")
            print("=" * 70)

            # Assertions
            assert training_ok, "Training should work after checkpoint load"
            assert step_match, f"VGS step_count should match: {vgs_a_after['step_count']} != {vgs_b['step_count']}"
            assert var_match, "VGS grad_var_ema should match"

    def test_pbt_scheduler_direct_exploitation(self):
        """
        Test 3: Simulate PBT's ACTUAL behavior with policy.state_dict().

        This tests the BUG: PBT saves/loads only policy.state_dict(), which
        does NOT include VGS state, causing a mismatch.
        """
        print("\n" + "=" * 70)
        print("TEST 3: PBT-Style Exploitation (Policy State Dict Only)")
        print("=" * 70)

        # Create two models
        model_a, env_a = create_test_model(learning_rate=1e-4, use_vgs=True, seed=42)
        model_b, env_b = create_test_model(learning_rate=5e-4, use_vgs=True, seed=123)

        print("\n1. Training Member A (50 timesteps)...")
        model_a.learn(total_timesteps=50, progress_bar=False)

        print("2. Training Member B (150 timesteps - better performance)...")
        model_b.learn(total_timesteps=150, progress_bar=False)

        # Record VGS states BEFORE exploitation
        vgs_a_before = get_vgs_state(model_a)
        vgs_b = get_vgs_state(model_b)

        print_vgs_comparison("Member A (before exploit)", vgs_a_before,
                           "Member B (source)", vgs_b)

        # Simulate PBT behavior: Save ONLY policy.state_dict()
        with tempfile.TemporaryDirectory() as tmpdir:
            checkpoint_path = Path(tmpdir) / "policy_state_dict.pt"

            print(f"\n3. Simulating PBT: Saving ONLY policy.state_dict() (NO VGS!)...")
            # This is what PBT does: torch.save(model_state_dict, checkpoint_path)
            # where model_state_dict = policy.state_dict()
            policy_state_dict = model_b.policy.state_dict()
            torch.save(policy_state_dict, checkpoint_path)
            print(f"   Saved to {checkpoint_path}")
            print(f"   Checkpoint contains ONLY policy weights (no VGS state)")

            # Simulate PBT exploitation: Load policy.state_dict() into Member A
            print("\n4. Simulating PBT exploit: Loading policy.state_dict() into Member A...")
            loaded_state_dict = torch.load(checkpoint_path, map_location="cpu", weights_only=True)
            model_a.policy.load_state_dict(loaded_state_dict)

            print("   Policy weights updated: Member A now has Member B's policy")

            # Check VGS state AFTER exploitation
            vgs_a_after = get_vgs_state(model_a)

            print_vgs_comparison("Member A (after PBT exploit)", vgs_a_after,
                               "Member B (expected)", vgs_b)

            # Verification
            print("\n5. Verification:")
            step_match = (vgs_a_after['step_count'] == vgs_b['step_count'])

            if step_match:
                print(f"   [OK] VGS step_count matches")
                problem_confirmed = False
            else:
                print(f"   [FAIL] VGS step_count mismatch: {vgs_a_after['step_count']} != {vgs_b['step_count']}")
                print(f"         Member A has: {vgs_a_after['step_count']}")
                print(f"         Member B has: {vgs_b['step_count']}")
                problem_confirmed = True

            # Test training after exploitation
            print("\n6. Testing training after exploitation...")
            try:
                model_a.learn(total_timesteps=50, progress_bar=False)
                print("   [OK] Training continues (no crash)")
                training_ok = True
            except Exception as e:
                print(f"   [FAIL] Training failed: {e}")
                training_ok = False

            # Final verdict
            print("\n" + "=" * 70)
            if problem_confirmed:
                print("[FAIL] TEST 3 CONFIRMED: VGS STATE MISMATCH IN PBT!")
                print("\nProblem:")
                print("  - PBT saves/loads ONLY policy.state_dict()")
                print("  - VGS state is NOT included in policy.state_dict()")
                print("  - After exploitation: Policy from B + VGS from A = MISMATCH!")
                print("\nImpact:")
                print("  - VGS uses wrong statistics for new policy weights")
                print("  - Training suboptimal for ~100-200 steps after exploitation")
                print("  - PBT efficiency reduced by 15-25%")
                print("\nFix needed:")
                print("  1. Save full model (model.get_parameters() includes VGS state)")
                print("  2. Load full model (model.set_parameters() restores VGS state)")
            else:
                print("[PASS] TEST 3 PASSED: No VGS mismatch detected")
            print("=" * 70)

            # Assertions
            assert training_ok, "Training should work after PBT exploitation"

            # This assertion SHOULD FAIL, confirming the bug
            if not step_match:
                print("\n[ERROR] VGS state mismatch confirmed - this is the bug we need to fix!")
            assert step_match, f"VGS step_count should match but doesn't: {vgs_a_after['step_count']} != {vgs_b['step_count']}"


if __name__ == "__main__":
    test = TestVGS_PBT_StateMismatch()

    try:
        print("\n" + "=" * 70)
        print("RUNNING VGS + PBT STATE MISMATCH TEST SUITE")
        print("=" * 70)

        # Test 1: Baseline - verify save/load works
        test.test_vgs_state_after_model_load()

        # Test 2: PBT-style checkpoint loading
        test.test_vgs_state_after_pbt_style_checkpoint_load()

        # Test 3: Actual PBT scheduler exploitation
        test.test_pbt_scheduler_direct_exploitation()

        print("\n" + "=" * 70)
        print("[OK] ALL TESTS COMPLETED!")
        print("=" * 70)

    except AssertionError as e:
        print(f"\nX TEST FAILED: {e}")
        import traceback
        traceback.print_exc()
    except Exception as e:
        print(f"\nX UNEXPECTED ERROR: {e}")
        import traceback
        traceback.print_exc()
