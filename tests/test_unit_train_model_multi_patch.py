"""
Comprehensive unit tests for train_model_multi_patch.py

This module tests the training pipeline components including:
- Metric functions (sharpe_ratio, sortino_ratio)
- Helper functions (_cfg_get, _coerce_timestamp, etc.)
- Callback classes (NanGuardCallback, SortinoPruningCallback, etc.)
- Data processing functions
- Environment wrappers
- Config extraction helpers

Coverage: All public and testable private functions
"""

import pytest
import numpy as np
import pandas as pd
import tempfile
import json
import os
import sys
from pathlib import Path
from unittest.mock import Mock, MagicMock, patch, PropertyMock
from datetime import datetime, date
from dataclasses import dataclass
from typing import Any, Dict, Optional
import torch
import torch.nn as nn

# Mock missing imports before importing the module under test
sys.modules.setdefault('services.futures_feature_flags', MagicMock())

# Import the module under test - use try/except for robustness
try:
    import train_model_multi_patch as tmp
    MODULE_LOADED = True
except ImportError as e:
    MODULE_LOADED = False
    tmp = MagicMock()


# =============================================================================
# Test Fixtures
# =============================================================================

@pytest.fixture
def sample_returns():
    """Sample return series for metric tests."""
    np.random.seed(42)
    return np.random.normal(0.001, 0.02, 100)


@pytest.fixture
def positive_returns():
    """Returns with positive bias."""
    np.random.seed(42)
    return np.abs(np.random.normal(0.005, 0.01, 100))


@pytest.fixture
def negative_returns():
    """Returns with negative bias."""
    np.random.seed(42)
    return -np.abs(np.random.normal(0.005, 0.01, 100))


@pytest.fixture
def sample_dataframe():
    """Sample DataFrame for data processing tests."""
    np.random.seed(42)
    dates = pd.date_range('2024-01-01', periods=100, freq='4h')
    return pd.DataFrame({
        'timestamp': dates.astype(np.int64) // 10**9,
        'open': np.random.uniform(100, 110, 100),
        'high': np.random.uniform(110, 120, 100),
        'low': np.random.uniform(90, 100, 100),
        'close': np.random.uniform(100, 110, 100),
        'volume': np.random.uniform(1000, 10000, 100),
    })


@pytest.fixture
def mock_env():
    """Mock environment for wrapper tests."""
    env = Mock()
    env.observation_space = Mock()
    env.observation_space.shape = (64,)
    env.action_space = Mock()
    env.action_space.shape = (1,)
    env.action_space.low = np.array([-1.0])
    env.action_space.high = np.array([1.0])
    env.reset = Mock(return_value=(np.zeros(64), {}))
    env.step = Mock(return_value=(np.zeros(64), 0.0, False, False, {}))
    return env


@pytest.fixture
def mock_model():
    """Mock model for callback tests."""
    model = Mock()
    model.logger = Mock()
    model.logger.record = Mock()
    model.policy = Mock()
    model.policy.optimizer = Mock()
    model.policy.optimizer.param_groups = [{'lr': 0.001}]
    model.num_timesteps = 1000
    model.parameters = Mock(return_value=iter([torch.nn.Parameter(torch.zeros(10))]))
    return model


@pytest.fixture
def mock_optuna_trial():
    """Mock Optuna trial for pruning callback tests."""
    trial = Mock()
    trial.number = 0
    trial.should_prune = Mock(return_value=False)
    trial.report = Mock()
    return trial


@pytest.fixture
def mock_vec_env():
    """Mock VecEnv for callback tests."""
    env = Mock()
    env.reset = Mock(return_value=np.zeros((1, 64)))
    env.step = Mock(return_value=(np.zeros((1, 64)), np.array([0.0]), np.array([False]), [{}]))
    return env


# =============================================================================
# Test _cfg_get Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestCfgGet:
    """Tests for the _cfg_get universal config getter."""

    def test_dict_access_simple(self):
        """Test simple dictionary access."""
        cfg = {'key': 'value'}
        assert tmp._cfg_get(cfg, 'key') == 'value'

    def test_dict_access_default(self):
        """Test default value when key not found."""
        cfg = {'key': 'value'}
        assert tmp._cfg_get(cfg, 'missing', 'default') == 'default'

    def test_dict_access_none_value(self):
        """Test that None values are returned correctly."""
        cfg = {'key': None}
        assert tmp._cfg_get(cfg, 'key', 'default') is None

    def test_dataclass_access(self):
        """Test dataclass attribute access."""
        @dataclass
        class Config:
            key: str = 'value'

        cfg = Config()
        assert tmp._cfg_get(cfg, 'key') == 'value'

    def test_empty_path(self):
        """Test empty path returns default."""
        cfg = {'key': 'value'}
        result = tmp._cfg_get(cfg, '', 'default')
        # Empty path behavior depends on implementation
        assert result is not None or result == 'default'

    def test_missing_nested_key(self):
        """Test missing nested key returns default."""
        cfg = {'level1': {'level2': 'value'}}
        result = tmp._cfg_get(cfg, 'level1.missing', 'default')
        assert result == 'default' or result is None


# =============================================================================
# Test _assign_nested Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestAssignNested:
    """Tests for nested dictionary assignment."""

    def test_simple_assignment(self):
        """Test simple key assignment."""
        d = {}
        tmp._assign_nested(d, 'key', 'value')
        assert d == {'key': 'value'}

    def test_nested_assignment(self):
        """Test nested key assignment with dot notation."""
        d = {}
        tmp._assign_nested(d, 'level1.level2.level3', 'value')
        assert d == {'level1': {'level2': {'level3': 'value'}}}

    def test_existing_nested_path(self):
        """Test assignment to existing nested path."""
        d = {'level1': {'existing': 'data'}}
        tmp._assign_nested(d, 'level1.level2', 'value')
        assert d == {'level1': {'existing': 'data', 'level2': 'value'}}

    def test_overwrite_existing_value(self):
        """Test overwriting existing value."""
        d = {'key': 'old'}
        tmp._assign_nested(d, 'key', 'new')
        assert d == {'key': 'new'}


# =============================================================================
# Test Timestamp Functions
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestCoerceTimestamp:
    """Tests for _coerce_timestamp function."""

    def test_integer_passthrough(self):
        """Test integer timestamp passthrough."""
        ts = 1704067200
        assert tmp._coerce_timestamp(ts) == ts

    def test_float_to_int(self):
        """Test float timestamp conversion."""
        ts = 1704067200.5
        assert tmp._coerce_timestamp(ts) == 1704067200

    def test_iso_string(self):
        """Test ISO format string conversion."""
        iso_str = "2024-01-01T00:00:00"
        result = tmp._coerce_timestamp(iso_str)
        assert isinstance(result, int)

    def test_date_string(self):
        """Test date string conversion."""
        date_str = "2024-01-01"
        result = tmp._coerce_timestamp(date_str)
        assert isinstance(result, int)

    def test_none_returns_none(self):
        """Test None input returns None."""
        assert tmp._coerce_timestamp(None) is None

    def test_invalid_string_raises(self):
        """Test invalid string raises ValueError."""
        with pytest.raises(ValueError):
            tmp._coerce_timestamp("invalid")

    def test_datetime_object_raises(self):
        """Test datetime object raises ValueError (not supported directly)."""
        dt = datetime(2024, 1, 1, 0, 0, 0)
        with pytest.raises(ValueError):
            tmp._coerce_timestamp(dt)


@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestFmtTs:
    """Tests for _fmt_ts timestamp formatting."""

    def test_format_timestamp(self):
        """Test timestamp formatting to ISO string."""
        ts = 1704067200  # 2024-01-01 00:00:00 UTC
        result = tmp._fmt_ts(ts)
        assert isinstance(result, str)
        assert '2024' in result

    def test_format_none(self):
        """Test None timestamp formatting."""
        result = tmp._fmt_ts(None)
        assert 'None' in str(result) or result is None


@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestNormalizeInterval:
    """Tests for _normalize_interval function."""

    def test_dict_with_start_end(self):
        """Test dict with start/end keys."""
        interval = {'start': 1704067200, 'end': 1704153600}
        result = tmp._normalize_interval(interval)
        assert result == (1704067200, 1704153600)

    def test_tuple_passthrough(self):
        """Test tuple passthrough."""
        interval = (1704067200, 1704153600)
        result = tmp._normalize_interval(interval)
        assert result == interval

    def test_list_conversion(self):
        """Test list to tuple conversion."""
        interval = [1704067200, 1704153600]
        result = tmp._normalize_interval(interval)
        assert result == (1704067200, 1704153600)

    def test_none_returns_none_tuple(self):
        """Test None returns (None, None)."""
        result = tmp._normalize_interval(None)
        assert result == (None, None)

    def test_invalid_raises_type_error(self):
        """Test invalid input raises TypeError."""
        with pytest.raises(TypeError):
            tmp._normalize_interval("invalid")


# =============================================================================
# Test Metric Functions
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestSharpeRatio:
    """Tests for sharpe_ratio function."""

    def test_positive_sharpe(self, positive_returns):
        """Test positive Sharpe ratio calculation."""
        result = tmp.sharpe_ratio(positive_returns)
        assert result > 0

    def test_negative_sharpe(self, negative_returns):
        """Test negative Sharpe ratio calculation."""
        result = tmp.sharpe_ratio(negative_returns)
        assert result < 0

    def test_zero_std_returns_zero(self):
        """Test zero standard deviation returns 0."""
        returns = np.array([0.01, 0.01, 0.01, 0.01])
        result = tmp.sharpe_ratio(returns)
        assert result == 0.0

    def test_empty_returns_zero(self):
        """Test empty returns array."""
        result = tmp.sharpe_ratio(np.array([]))
        assert result == 0.0

    def test_single_return_zero(self):
        """Test single return value returns 0 (insufficient data)."""
        result = tmp.sharpe_ratio(np.array([0.01]))
        assert result == 0.0

    def test_two_returns_zero(self):
        """Test two return values returns 0 (insufficient data)."""
        result = tmp.sharpe_ratio(np.array([0.01, 0.02]))
        assert result == 0.0

    def test_three_returns_valid(self):
        """Test three return values gives valid result."""
        result = tmp.sharpe_ratio(np.array([0.01, 0.02, 0.03]))
        assert isinstance(result, float)

    def test_annualization_factor(self, sample_returns):
        """Test annualization factor application."""
        daily_sqrt = np.sqrt(252)
        result = tmp.sharpe_ratio(sample_returns, annualization_sqrt=daily_sqrt)
        assert isinstance(result, (int, float))

    def test_risk_free_rate(self, sample_returns):
        """Test risk-free rate subtraction."""
        rf = 0.0001  # Daily risk-free rate
        result = tmp.sharpe_ratio(sample_returns, risk_free_rate=rf)
        assert isinstance(result, (int, float))


@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestSortinoRatio:
    """Tests for sortino_ratio function."""

    def test_positive_sortino(self, positive_returns):
        """Test positive Sortino ratio calculation."""
        result = tmp.sortino_ratio(positive_returns)
        # All positive returns means no downside deviation, but with fallback
        assert isinstance(result, (int, float))

    def test_negative_sortino(self, negative_returns):
        """Test negative Sortino ratio calculation."""
        result = tmp.sortino_ratio(negative_returns)
        assert result < 0

    def test_mixed_returns(self, sample_returns):
        """Test mixed returns."""
        result = tmp.sortino_ratio(sample_returns)
        assert isinstance(result, (int, float))

    def test_empty_returns_zero(self):
        """Test empty returns array."""
        result = tmp.sortino_ratio(np.array([]))
        assert result == 0.0

    def test_small_sample_returns_zero(self):
        """Test small sample returns 0."""
        result = tmp.sortino_ratio(np.array([0.01, 0.02]))
        assert result == 0.0

    def test_annualization_factor(self, sample_returns):
        """Test annualization factor application."""
        daily_sqrt = np.sqrt(252)
        result = tmp.sortino_ratio(sample_returns, annualization_sqrt=daily_sqrt)
        assert isinstance(result, (int, float))


@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestResolveAnnSqrt:
    """Tests for _resolve_ann_sqrt function."""

    def test_explicit_annualization(self):
        """Test explicit annualization factor."""
        result = tmp._resolve_ann_sqrt(np.sqrt(252))
        assert result == pytest.approx(np.sqrt(252))

    def test_none_returns_default(self):
        """Test None returns default annualization."""
        result = tmp._resolve_ann_sqrt(None)
        # Should return the default value (defined in module)
        assert result > 0


# =============================================================================
# Test Callback Classes
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestNanGuardCallback:
    """Tests for NanGuardCallback."""

    def test_initialization(self):
        """Test callback initialization."""
        callback = tmp.NanGuardCallback(threshold=100.0, verbose=0)
        assert callback.threshold == 100.0

    def test_initialization_default(self):
        """Test callback initialization with defaults."""
        callback = tmp.NanGuardCallback()
        assert callback.threshold == float("inf")

    def test_model_attribute_initialized(self):
        """Test model attribute is initialized."""
        callback = tmp.NanGuardCallback()
        assert callback.model is None


@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestSortinoPruningCallback:
    """Tests for SortinoPruningCallback."""

    def test_initialization(self, mock_optuna_trial, mock_vec_env):
        """Test callback initialization."""
        callback = tmp.SortinoPruningCallback(
            trial=mock_optuna_trial,
            eval_env=mock_vec_env,
            n_eval_episodes=5,
            eval_freq=1000
        )
        assert callback.trial == mock_optuna_trial
        assert callback.n_eval_episodes == 5
        assert callback.eval_freq == 1000

    def test_model_attribute_initialized(self, mock_optuna_trial, mock_vec_env):
        """Test model attribute is initialized."""
        callback = tmp.SortinoPruningCallback(
            trial=mock_optuna_trial,
            eval_env=mock_vec_env,
        )
        assert callback.model is None


# =============================================================================
# Test Boolean Coercion (via _coerce_type or similar if exists)
# =============================================================================

# NOTE: _coerce_bool function does not exist in the module.
# Boolean coercion is handled via other means (YAML parsing, etc.)
# Tests for boolean coercion removed.


# =============================================================================
# Test Environment Wrapper Functions
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestFreezeVecnormalize:
    """Tests for _freeze_vecnormalize function."""

    def test_freeze_sets_training_false(self):
        """Test that freeze sets training to False."""
        mock_vecnorm = Mock()
        mock_vecnorm.training = True

        tmp._freeze_vecnormalize(mock_vecnorm)

        assert mock_vecnorm.training is False

    def test_freeze_with_none_raises_attribute_error(self):
        """Test freeze with None input raises AttributeError."""
        # None doesn't have .training attribute
        with pytest.raises(AttributeError):
            tmp._freeze_vecnormalize(None)


# =============================================================================
# Test Multiprocessing Configuration
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestConfigureStartMethod:
    """Tests for _configure_start_method function."""

    def test_does_not_raise(self):
        """Test that function doesn't raise exceptions."""
        # Should handle any platform gracefully
        try:
            tmp._configure_start_method()
        except Exception as e:
            pytest.fail(f"_configure_start_method raised {e}")

    def test_idempotent(self):
        """Test that multiple calls are safe."""
        tmp._configure_start_method()
        tmp._configure_start_method()
        # Should not raise


class TestExtractGradSanity:
    """Tests for _extract_grad_sanity function."""

    def test_extract_flag_value(self):
        """Test extracting --grad-sanity flag."""
        argv = ['--config', 'test.yaml', '--grad-sanity', '2']

        # Access the function from main block context
        def _extract_grad_sanity(argv):
            for idx, arg in enumerate(argv):
                if arg == "--grad-sanity":
                    if idx + 1 < len(argv) and not argv[idx + 1].startswith("--"):
                        return argv[idx + 1]
                    return "1"
                if arg.startswith("--grad-sanity="):
                    value = arg.split("=", 1)[1]
                    return value if value else "1"
            return None

        result = _extract_grad_sanity(argv)
        assert result == '2'

    def test_extract_flag_equals_syntax(self):
        """Test extracting --grad-sanity=value syntax."""
        argv = ['--config', 'test.yaml', '--grad-sanity=3']

        def _extract_grad_sanity(argv):
            for idx, arg in enumerate(argv):
                if arg == "--grad-sanity":
                    if idx + 1 < len(argv) and not argv[idx + 1].startswith("--"):
                        return argv[idx + 1]
                    return "1"
                if arg.startswith("--grad-sanity="):
                    value = arg.split("=", 1)[1]
                    return value if value else "1"
            return None

        result = _extract_grad_sanity(argv)
        assert result == '3'

    def test_no_flag_returns_none(self):
        """Test no flag returns None."""
        argv = ['--config', 'test.yaml']

        def _extract_grad_sanity(argv):
            for idx, arg in enumerate(argv):
                if arg == "--grad-sanity":
                    if idx + 1 < len(argv) and not argv[idx + 1].startswith("--"):
                        return argv[idx + 1]
                    return "1"
                if arg.startswith("--grad-sanity="):
                    value = arg.split("=", 1)[1]
                    return value if value else "1"
            return None

        result = _extract_grad_sanity(argv)
        assert result is None


# =============================================================================
# Test Interval Formatting
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestFormatInterval:
    """Tests for _format_interval function."""

    def test_format_valid_interval(self):
        """Test formatting valid interval."""
        interval = (1704067200, 1704153600)

        result = tmp._format_interval(interval)
        assert isinstance(result, str)


# =============================================================================
# Test Edge Cases and Error Handling
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestEdgeCases:
    """Tests for edge cases and error handling."""

    def test_sharpe_with_all_zeros(self):
        """Test Sharpe ratio with all zero returns."""
        returns = np.zeros(100)
        result = tmp.sharpe_ratio(returns)
        assert result == 0.0

    def test_sortino_with_all_zeros(self):
        """Test Sortino ratio with all zero returns."""
        returns = np.zeros(100)
        result = tmp.sortino_ratio(returns)
        assert result == 0.0

    def test_cfg_get_with_none_config(self):
        """Test _cfg_get with None config."""
        result = tmp._cfg_get(None, 'key', 'default')
        assert result == 'default'

    def test_coerce_timestamp_with_large_value(self):
        """Test _coerce_timestamp with large value."""
        large_ts = 2**32
        result = tmp._coerce_timestamp(large_ts)
        assert result == large_ts

    def test_normalize_interval_with_empty_dict(self):
        """Test _normalize_interval with empty dict returns (None, None)."""
        # Empty dict with missing 'start'/'end' keys returns (None, None)
        result = tmp._normalize_interval({})
        assert result == (None, None)


@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestIntegrationScenarios:
    """Integration tests for common usage scenarios."""

    def test_full_metric_calculation_workflow(self, sample_returns):
        """Test full metric calculation workflow."""
        # Calculate both metrics
        sharpe = tmp.sharpe_ratio(sample_returns, annualization_sqrt=np.sqrt(252))
        sortino = tmp.sortino_ratio(sample_returns, annualization_sqrt=np.sqrt(252))

        # Both should be finite
        assert np.isfinite(sharpe) or sharpe == 0.0
        assert np.isfinite(sortino) or sortino == 0.0


# =============================================================================
# Test PopArt Holdout Loader Wrapper
# =============================================================================

# NOTE: _PopArtHoldoutLoaderWrapper is part of the DISABLED PopArt system.
# The class requires complex dependencies (path, batch_cls, etc.) that are
# not easily mockable for unit tests. PopArt is disabled at initialization
# and this code path is unused in production. Tests skipped.


# =============================================================================
# Test Sharpe/Sortino Edge Cases
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestMetricEdgeCases:
    """Additional edge case tests for metric functions."""

    def test_sharpe_with_inf_returns(self):
        """Test Sharpe ratio with infinity returns."""
        returns = np.array([0.01, float('inf'), 0.02])
        result = tmp.sharpe_ratio(returns)
        # Should handle gracefully
        assert isinstance(result, float)

    def test_sharpe_with_nan_returns(self):
        """Test Sharpe ratio with NaN returns."""
        returns = np.array([0.01, float('nan'), 0.02])
        result = tmp.sharpe_ratio(returns)
        # Should handle gracefully
        assert isinstance(result, float)

    def test_sortino_with_all_positive(self):
        """Test Sortino with all positive returns."""
        returns = np.array([0.01, 0.02, 0.03, 0.01, 0.02])
        result = tmp.sortino_ratio(returns)
        # No downside, should use std fallback
        assert isinstance(result, float)

    def test_sharpe_large_sample(self):
        """Test Sharpe ratio with large sample."""
        np.random.seed(42)
        returns = np.random.normal(0.001, 0.02, 10000)
        result = tmp.sharpe_ratio(returns)
        assert isinstance(result, float)
        assert np.isfinite(result)


# =============================================================================
# Test _export_training_dataset Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestExportTrainingDataset:
    """Tests for _export_training_dataset function."""

    def test_export_simple_dataframes(self, tmp_path):
        """Test exporting simple dataframes."""
        dfs = {
            'BTCUSDT': pd.DataFrame({
                'timestamp': [1704067200, 1704070800, 1704074400],
                'close': [42000.0, 42100.0, 42200.0],
                'role': ['train', 'train', 'val'],
            })
        }

        result = tmp._export_training_dataset(
            dfs,
            role_column='role',
            timestamp_column='timestamp',
            artifacts_dir=tmp_path,
            split_version='v1',
            inferred_test=False,
        )

        assert result.exists()
        assert (tmp_path / 'training_summary.json').exists()

    def test_export_empty_raises(self, tmp_path):
        """Test that empty dfs raises ValueError."""
        with pytest.raises(ValueError, match="No dataframes"):
            tmp._export_training_dataset(
                {},
                role_column='role',
                timestamp_column='timestamp',
                artifacts_dir=tmp_path,
                split_version='v1',
                inferred_test=False,
            )

    def test_export_all_empty_dataframes_raises(self, tmp_path):
        """Test that all empty dataframes raises ValueError."""
        dfs = {'BTCUSDT': pd.DataFrame()}

        with pytest.raises(ValueError, match="empty"):
            tmp._export_training_dataset(
                dfs,
                role_column='role',
                timestamp_column='timestamp',
                artifacts_dir=tmp_path,
                split_version='v1',
                inferred_test=False,
            )

    def test_export_missing_timestamp_raises(self, tmp_path):
        """Test that missing timestamp column raises KeyError."""
        dfs = {
            'BTCUSDT': pd.DataFrame({
                'close': [42000.0, 42100.0],
            })
        }

        with pytest.raises(KeyError):
            tmp._export_training_dataset(
                dfs,
                role_column='role',
                timestamp_column='timestamp',
                artifacts_dir=tmp_path,
                split_version='v1',
                inferred_test=False,
            )

    def test_export_multiple_symbols(self, tmp_path):
        """Test exporting multiple symbols."""
        dfs = {
            'BTCUSDT': pd.DataFrame({
                'timestamp': [1704067200, 1704070800],
                'close': [42000.0, 42100.0],
            }),
            'ETHUSDT': pd.DataFrame({
                'timestamp': [1704067200, 1704070800],
                'close': [2200.0, 2210.0],
            })
        }

        result = tmp._export_training_dataset(
            dfs,
            role_column='role',
            timestamp_column='timestamp',
            artifacts_dir=tmp_path,
            split_version='v1',
            inferred_test=True,
        )

        assert result.exists()

        # Check summary
        with open(tmp_path / 'training_summary.json') as f:
            summary = json.load(f)
        assert len(summary['symbols']) == 2


# =============================================================================
# Test _install_torch_intrinsic_stub Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestInstallTorchIntrinsicStub:
    """Tests for _install_torch_intrinsic_stub function."""

    def test_stub_installation(self):
        """Test that stub installation doesn't raise."""
        # The function should be safe to call
        try:
            tmp._install_torch_intrinsic_stub()
        except Exception as e:
            pytest.fail(f"_install_torch_intrinsic_stub raised {e}")

    def test_stub_idempotent(self):
        """Test that multiple calls are idempotent."""
        tmp._install_torch_intrinsic_stub()
        tmp._install_torch_intrinsic_stub()
        # Should not raise


# =============================================================================
# Test _coerce_positive_seconds Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestCoercePositiveSeconds:
    """Tests for _coerce_positive_seconds function."""

    def test_positive_float(self):
        """Test positive float value."""
        result = tmp._coerce_positive_seconds(3600.0)
        assert result == 3600.0

    def test_positive_int(self):
        """Test positive int value."""
        result = tmp._coerce_positive_seconds(3600)
        assert result == 3600.0

    def test_zero_returns_none(self):
        """Test zero returns None."""
        result = tmp._coerce_positive_seconds(0)
        assert result is None

    def test_negative_returns_none(self):
        """Test negative returns None."""
        result = tmp._coerce_positive_seconds(-100)
        assert result is None

    def test_ms_conversion(self):
        """Test milliseconds conversion."""
        result = tmp._coerce_positive_seconds(3600000, assumes_ms=True)
        assert result == 3600.0

    def test_nan_returns_none(self):
        """Test NaN returns None."""
        result = tmp._coerce_positive_seconds(float('nan'))
        assert result is None

    def test_inf_returns_none(self):
        """Test Infinity returns None."""
        result = tmp._coerce_positive_seconds(float('inf'))
        assert result is None

    def test_string_returns_none(self):
        """Test string value returns None."""
        result = tmp._coerce_positive_seconds("invalid")
        assert result is None

    def test_none_returns_none(self):
        """Test None returns None."""
        result = tmp._coerce_positive_seconds(None)
        assert result is None


# =============================================================================
# Test _resolve_bar_seconds Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestResolveBarSeconds:
    """Tests for _resolve_bar_seconds function."""

    def test_object_with_bar_interval_seconds(self):
        """Test object with bar_interval_seconds attribute."""
        obj = Mock()
        obj.bar_interval_seconds = 3600.0

        result = tmp._resolve_bar_seconds(obj)
        assert result == 3600.0

    def test_object_with_bar_interval_ms(self):
        """Test object with bar_interval_ms attribute."""
        obj = Mock()
        obj.bar_interval_ms = 3600000
        # Remove other attributes
        del obj.bar_interval_seconds
        del obj.bar_seconds

        result = tmp._resolve_bar_seconds(obj)
        assert result == 3600.0

    def test_none_returns_none(self):
        """Test None returns None."""
        result = tmp._resolve_bar_seconds(None)
        assert result is None

    def test_object_with_get_bar_interval_seconds_method(self):
        """Test object with get_bar_interval_seconds method."""
        obj = Mock()
        obj.get_bar_interval_seconds = Mock(return_value=7200.0)

        result = tmp._resolve_bar_seconds(obj)
        assert result == 7200.0


# =============================================================================
# Test _annualization_sqrt_from_env Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestAnnualizationSqrtFromEnv:
    """Tests for _annualization_sqrt_from_env function."""

    def test_with_known_bar_seconds(self):
        """Test with known bar seconds."""
        obj = Mock()
        obj.bar_interval_seconds = 3600.0  # 1 hour

        ann_sqrt, bar_sec = tmp._annualization_sqrt_from_env(obj)

        assert bar_sec == 3600.0
        assert ann_sqrt > 0

    def test_with_none_returns_default(self):
        """Test with None returns default."""
        ann_sqrt, bar_sec = tmp._annualization_sqrt_from_env(None)

        assert bar_sec is None
        # Should use DEFAULT_ANNUALIZATION_SQRT
        assert ann_sqrt == tmp._DEFAULT_ANNUALIZATION_SQRT


# =============================================================================
# Test _value_changed Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestValueChanged:
    """Tests for _value_changed function."""

    def test_both_none_returns_false(self):
        """Test both None returns False."""
        result = tmp._value_changed(None, None)
        assert result is False

    def test_one_none_returns_true(self):
        """Test one None returns True."""
        assert tmp._value_changed(None, 1.0) is True
        assert tmp._value_changed(1.0, None) is True

    def test_equal_values_returns_false(self):
        """Test equal values returns False."""
        result = tmp._value_changed(1.0, 1.0)
        assert result is False

    def test_different_values_returns_true(self):
        """Test different values returns True."""
        result = tmp._value_changed(1.0, 2.0)
        assert result is True

    def test_close_values_within_tolerance(self):
        """Test close values within tolerance returns False."""
        result = tmp._value_changed(1.0, 1.0 + 1e-12)
        assert result is False


# =============================================================================
# Test _flatten_candidates Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestFlattenCandidates:
    """Tests for _flatten_candidates function."""

    def test_simple_list(self):
        """Test flattening simple list."""
        values = [1, 2, 3]
        result = list(tmp._flatten_candidates(values))
        assert result == [1, 2, 3]

    def test_nested_list(self):
        """Test flattening nested list."""
        values = [[1, 2], [3, 4]]
        result = list(tmp._flatten_candidates(values))
        assert result == [1, 2, 3, 4]

    def test_mixed_types(self):
        """Test flattening mixed types."""
        values = [1, [2, 3], (4, 5)]
        result = list(tmp._flatten_candidates(values))
        assert result == [1, 2, 3, 4, 5]

    def test_none_filtered(self):
        """Test None values are filtered."""
        values = [1, None, 2]
        result = list(tmp._flatten_candidates(values))
        assert result == [1, 2]

    def test_single_value(self):
        """Test single value."""
        result = list(tmp._flatten_candidates(42))
        assert result == [42]

    def test_empty_list(self):
        """Test empty list."""
        result = list(tmp._flatten_candidates([]))
        assert result == []


# =============================================================================
# Test AdversarialCallback Class
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestAdversarialCallback:
    """Tests for AdversarialCallback class."""

    def test_initialization(self):
        """Test callback initialization."""
        mock_env = Mock()
        callback = tmp.AdversarialCallback(
            eval_env=mock_env,
            eval_freq=1000,
            regimes=['normal', 'crisis'],
            regime_duration=100,
        )

        assert callback.eval_env == mock_env
        assert callback.eval_freq == 1000
        assert callback.regimes == ['normal', 'crisis']
        assert callback.regime_duration == 100

    def test_model_attribute_initialized(self):
        """Test model attribute is initialized to None."""
        mock_env = Mock()
        callback = tmp.AdversarialCallback(
            eval_env=mock_env,
            eval_freq=1000,
            regimes=['normal'],
            regime_duration=100,
        )

        assert callback.model is None

    def test_get_regime_metrics_empty(self):
        """Test get_regime_metrics returns empty dict initially."""
        mock_env = Mock()
        callback = tmp.AdversarialCallback(
            eval_env=mock_env,
            eval_freq=1000,
            regimes=['normal'],
            regime_duration=100,
        )

        assert callback.get_regime_metrics() == {}


# =============================================================================
# Test _wrap_action_space_if_needed Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestWrapActionSpaceIfNeeded:
    """Tests for _wrap_action_space_if_needed function."""

    def test_basic_wrapping(self, mock_env):
        """Test basic wrapping."""
        from gymnasium import spaces

        # Create a mock env with Box action space
        mock_env.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)

        result = tmp._wrap_action_space_if_needed(mock_env)

        # Should return wrapped or original env
        assert result is not None

    def test_long_only_wrapping(self, mock_env):
        """Test long-only mode wrapping."""
        from gymnasium import spaces

        mock_env.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)

        result = tmp._wrap_action_space_if_needed(mock_env, long_only=True)

        assert result is not None


# =============================================================================
# Test _wrap_futures_env_if_needed Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestWrapFuturesEnvIfNeeded:
    """Tests for _wrap_futures_env_if_needed function."""

    def test_non_futures_returns_original(self, mock_env):
        """Test non-futures asset class returns original env."""
        result = tmp._wrap_futures_env_if_needed(
            mock_env,
            asset_class='spot',
        )

        assert result is mock_env

    def test_crypto_futures_wrapping(self, mock_env):
        """Test crypto futures wrapping (may be disabled by feature flag)."""
        result = tmp._wrap_futures_env_if_needed(
            mock_env,
            asset_class='crypto_futures',
            futures_config={'initial_leverage': 10},
        )

        # Result depends on feature flag
        assert result is not None


# =============================================================================
# Test _PopArtHoldoutLoaderWrapper Class
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestPopArtHoldoutLoaderWrapper:
    """Tests for _PopArtHoldoutLoaderWrapper class."""

    def test_initialization(self, tmp_path):
        """Test wrapper initialization."""
        batch_cls = Mock()

        wrapper = tmp._PopArtHoldoutLoaderWrapper(
            path=tmp_path / 'holdout.npz',
            batch_size=64,
            seed=42,
            min_samples=100,
            batch_cls=batch_cls,
        )

        assert wrapper._batch_size == 64
        assert wrapper._seed == 42
        assert wrapper._min_samples == 100

    def test_call_returns_none_when_file_missing(self, tmp_path):
        """Test __call__ returns None when file is missing and no env attached."""
        batch_cls = Mock()

        wrapper = tmp._PopArtHoldoutLoaderWrapper(
            path=tmp_path / 'nonexistent.npz',
            batch_size=64,
            seed=42,
            min_samples=100,
            batch_cls=batch_cls,
        )

        result = wrapper()
        assert result is None

    def test_attach_env(self, tmp_path):
        """Test attach_env method."""
        batch_cls = Mock()
        mock_env = Mock()

        wrapper = tmp._PopArtHoldoutLoaderWrapper(
            path=tmp_path / 'holdout.npz',
            batch_size=64,
            seed=42,
            min_samples=100,
            batch_cls=batch_cls,
        )

        wrapper.attach_env(mock_env)

        assert wrapper._env is mock_env

    def test_call_with_valid_npz_file(self, tmp_path):
        """Test __call__ with valid NPZ file."""
        batch_cls = Mock()

        # Create valid NPZ file
        npz_path = tmp_path / 'holdout.npz'
        obs = np.random.randn(100, 64).astype(np.float32)
        returns = np.random.randn(100, 1).astype(np.float32)
        starts = np.zeros(100, dtype=np.float32)

        np.savez_compressed(str(npz_path), obs=obs, returns=returns, episode_starts=starts)

        wrapper = tmp._PopArtHoldoutLoaderWrapper(
            path=npz_path,
            batch_size=32,
            seed=42,
            min_samples=50,
            batch_cls=batch_cls,
        )

        result = wrapper()

        # batch_cls should have been called
        batch_cls.assert_called_once()

    def test_sample_actions_box_space(self):
        """Test _sample_actions with Box action space."""
        try:
            import gym
        except ImportError:
            pytest.skip("gym not available")

        # Use real gym.spaces.Box instead of mock (isinstance check needs real type)
        action_space = gym.spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)
        rng = np.random.default_rng(42)

        result = tmp._PopArtHoldoutLoaderWrapper._sample_actions(
            action_space, num_envs=4, rng=rng, gym_module=gym
        )

        assert result.shape[0] == 4
        assert result.shape[1] == 1  # matches action_space.shape

    def test_sample_actions_discrete_space(self):
        """Test _sample_actions with Discrete action space."""
        try:
            import gym
        except ImportError:
            pytest.skip("gym not available")

        # Use real gym.spaces.Discrete instead of mock (isinstance check needs real type)
        action_space = gym.spaces.Discrete(5)
        rng = np.random.default_rng(42)

        result = tmp._PopArtHoldoutLoaderWrapper._sample_actions(
            action_space, num_envs=4, rng=rng, gym_module=gym
        )

        assert result.shape[0] == 4
        # Discrete actions should be integers in range [0, n)
        assert all(0 <= a < 5 for a in result)


# =============================================================================
# Test _file_sha256 Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestFileSha256:
    """Tests for _file_sha256 function."""

    def test_valid_file(self, tmp_path):
        """Test SHA256 of valid file."""
        test_file = tmp_path / 'test.txt'
        test_file.write_text('test content')

        result = tmp._file_sha256(str(test_file))

        assert result is not None
        assert len(result) == 64  # SHA256 hex length

    def test_missing_file_returns_none(self):
        """Test missing file returns None."""
        result = tmp._file_sha256('/nonexistent/path')
        assert result is None

    def test_none_path_returns_none(self):
        """Test None path returns None."""
        result = tmp._file_sha256(None)
        assert result is None

    def test_empty_path_returns_none(self):
        """Test empty path returns None."""
        result = tmp._file_sha256('')
        assert result is None


# =============================================================================
# Test _build_popart_holdout_loader Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestBuildPopartHoldoutLoader:
    """Tests for _build_popart_holdout_loader function."""

    def test_returns_none_when_disabled(self):
        """Test returns None when PopArt is disabled."""
        controller_cfg = {'enabled': False}

        result = tmp._build_popart_holdout_loader(controller_cfg)

        assert result is None

    def test_returns_none_even_when_enabled(self):
        """Test returns None even when enabled (PopArt is disabled globally)."""
        controller_cfg = {'enabled': True}

        result = tmp._build_popart_holdout_loader(controller_cfg)

        # PopArt is disabled, so should still return None with warning
        assert result is None


# =============================================================================
# Test _log_annualization Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestLogAnnualization:
    """Tests for _log_annualization function."""

    def test_log_with_known_bar_seconds(self):
        """Test logging with known bar seconds."""
        # Should not raise
        tmp._log_annualization("test", 15.78, 3600.0)

    def test_log_with_unknown_bar_seconds(self):
        """Test logging with unknown bar seconds."""
        # Should not raise
        tmp._log_annualization("test", 15.78, None)


# =============================================================================
# Test _snapshot_model_param_keys Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestSnapshotModelParamKeys:
    """Tests for _snapshot_model_param_keys function."""

    def test_with_dict_params(self):
        """Test with dict params."""
        cfg = Mock()
        cfg.model = Mock()
        cfg.model.params = {'lr': 0.001, 'gamma': 0.99}

        result = tmp._snapshot_model_param_keys(cfg)

        assert 'lr' in result
        assert 'gamma' in result

    def test_with_none_model(self):
        """Test with None model."""
        cfg = Mock()
        cfg.model = None

        result = tmp._snapshot_model_param_keys(cfg)

        assert result == set()


# =============================================================================
# Test _propagate_train_window_alias Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestPropagateTrainWindowAlias:
    """Tests for _propagate_train_window_alias function."""

    def test_start_ts_alias(self):
        """Test start_ts sets both aliases."""
        block = {}
        tmp._propagate_train_window_alias(block, 'start_ts', 1000)

        assert block['start_ts'] == 1000
        assert block['train_start_ts'] == 1000

    def test_train_start_ts_alias(self):
        """Test train_start_ts sets both aliases."""
        block = {}
        tmp._propagate_train_window_alias(block, 'train_start_ts', 2000)

        assert block['start_ts'] == 2000
        assert block['train_start_ts'] == 2000

    def test_end_ts_alias(self):
        """Test end_ts sets both aliases."""
        block = {}
        tmp._propagate_train_window_alias(block, 'end_ts', 3000)

        assert block['end_ts'] == 3000
        assert block['train_end_ts'] == 3000

    def test_train_end_ts_alias(self):
        """Test train_end_ts sets both aliases."""
        block = {}
        tmp._propagate_train_window_alias(block, 'train_end_ts', 4000)

        assert block['end_ts'] == 4000
        assert block['train_end_ts'] == 4000

    def test_dotted_key_ignored(self):
        """Test dotted keys are ignored."""
        block = {}
        tmp._propagate_train_window_alias(block, 'foo.start_ts', 1000)

        assert 'start_ts' not in block
        assert 'train_start_ts' not in block

    def test_unrelated_key_ignored(self):
        """Test unrelated keys don't affect aliases."""
        block = {}
        tmp._propagate_train_window_alias(block, 'other_key', 1000)

        assert 'start_ts' not in block
        assert 'end_ts' not in block


# =============================================================================
# Test _ensure_train_window_aliases Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestEnsureTrainWindowAliases:
    """Tests for _ensure_train_window_aliases function."""

    def test_start_ts_propagates_to_train_start_ts(self):
        """Test start_ts propagates when train_start_ts is None."""
        block = {'start_ts': 1000}
        tmp._ensure_train_window_aliases(block)

        assert block['train_start_ts'] == 1000

    def test_train_start_ts_propagates_to_start_ts(self):
        """Test train_start_ts propagates when start_ts is None."""
        block = {'train_start_ts': 2000}
        tmp._ensure_train_window_aliases(block)

        assert block['start_ts'] == 2000

    def test_end_ts_propagates_to_train_end_ts(self):
        """Test end_ts propagates when train_end_ts is None."""
        block = {'end_ts': 3000}
        tmp._ensure_train_window_aliases(block)

        assert block['train_end_ts'] == 3000

    def test_train_end_ts_propagates_to_end_ts(self):
        """Test train_end_ts propagates when end_ts is None."""
        block = {'train_end_ts': 4000}
        tmp._ensure_train_window_aliases(block)

        assert block['end_ts'] == 4000

    def test_mismatch_uses_train_start_ts(self):
        """Test mismatch between start_ts and train_start_ts."""
        block = {'start_ts': 1000, 'train_start_ts': 2000}
        tmp._ensure_train_window_aliases(block)

        assert block['start_ts'] == 2000  # train_start_ts wins

    def test_empty_block_unchanged(self):
        """Test empty block stays empty."""
        block = {}
        tmp._ensure_train_window_aliases(block)

        assert 'start_ts' not in block
        assert 'train_start_ts' not in block


# =============================================================================
# Test _extract_env_runtime_overrides Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestExtractEnvRuntimeOverrides:
    """Tests for _extract_env_runtime_overrides function."""

    def test_none_returns_empty(self):
        """Test None input returns empty dict."""
        kwargs, decision = tmp._extract_env_runtime_overrides(None)

        assert kwargs == {}
        assert decision is None

    def test_empty_mapping_returns_empty(self):
        """Test empty mapping returns empty dict."""
        kwargs, decision = tmp._extract_env_runtime_overrides({})

        assert kwargs == {}
        assert decision is None

    def test_decision_timing_extraction(self):
        """Test decision_timing is extracted."""
        env_block = {'decision_timing': 'CLOSE_TO_OPEN'}
        kwargs, decision = tmp._extract_env_runtime_overrides(env_block)

        from trading_patchnew import DecisionTiming
        assert decision == DecisionTiming.CLOSE_TO_OPEN

    def test_decision_mode_alias(self):
        """Test decision_mode alias is supported."""
        env_block = {'decision_mode': 'INTRA_HOUR_WITH_LATENCY'}
        kwargs, decision = tmp._extract_env_runtime_overrides(env_block)

        from trading_patchnew import DecisionTiming
        assert decision == DecisionTiming.INTRA_HOUR_WITH_LATENCY

    def test_no_trade_enabled(self):
        """Test no_trade.enabled extraction."""
        env_block = {'no_trade': {'enabled': True}}
        kwargs, decision = tmp._extract_env_runtime_overrides(env_block)

        assert kwargs.get('no_trade_enabled') is True

    def test_no_trade_policy_ignore(self):
        """Test no_trade.policy extraction with ignore."""
        env_block = {'no_trade': {'enabled': True, 'policy': 'ignore'}}
        kwargs, decision = tmp._extract_env_runtime_overrides(env_block)

        assert kwargs.get('no_trade_policy') == 'ignore'

    def test_session_section_extraction(self):
        """Test session section extraction."""
        env_block = {'session': {'start_time': '09:30', 'end_time': '16:00'}}
        kwargs, decision = tmp._extract_env_runtime_overrides(env_block)

        assert kwargs.get('session') == {'start_time': '09:30', 'end_time': '16:00'}


# =============================================================================
# Test _extract_offline_split_overrides Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestExtractOfflineSplitOverrides:
    """Tests for _extract_offline_split_overrides function."""

    def test_none_payload_returns_empty(self):
        """Test None payload returns empty dict."""
        result = tmp._extract_offline_split_overrides(None, 'dataset1')

        assert result == {}

    def test_empty_payload_returns_empty(self):
        """Test empty payload returns empty dict."""
        result = tmp._extract_offline_split_overrides({}, 'dataset1')

        assert result == {}

    def test_with_splits_block(self):
        """Test extraction from splits block."""
        payload = {
            'datasets': {
                'dataset1': {
                    'splits': {
                        'time': {
                            'train': {'start_ts': 1000, 'end_ts': 2000},
                            'val': {'start_ts': 2000, 'end_ts': 3000}
                        }
                    }
                }
            }
        }
        result = tmp._extract_offline_split_overrides(payload, 'dataset1')

        assert 'train' in result
        assert 'val' in result

    def test_with_direct_phases(self):
        """Test extraction from direct phase keys."""
        payload = {
            'datasets': {
                'dataset1': {
                    'train': {'start_ts': 1000, 'end_ts': 2000}
                }
            }
        }
        result = tmp._extract_offline_split_overrides(payload, 'dataset1')

        # Depends on internal logic
        assert isinstance(result, dict)


# =============================================================================
# Test _normalize_interval Edge Cases
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestNormalizeIntervalAdvanced:
    """Advanced tests for _normalize_interval function."""

    def test_dict_with_from_to(self):
        """Test dict with from/to keys."""
        result = tmp._normalize_interval({'from': 1000, 'to': 2000})

        assert result[0] == 1000
        assert result[1] == 2000

    def test_invalid_interval_raises(self):
        """Test invalid interval (end before start) raises."""
        with pytest.raises(ValueError):
            tmp._normalize_interval({'start_ts': 2000, 'end_ts': 1000})

    def test_list_interval(self):
        """Test list interval format."""
        result = tmp._normalize_interval([1000, 2000])

        assert result == (1000, 2000)


# =============================================================================
# Test _snapshot_model_param_keys Advanced Cases
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestSnapshotModelParamKeysAdvanced:
    """Advanced tests for _snapshot_model_param_keys function."""

    def test_with_params_having_dict_method(self):
        """Test with params having dict() method."""
        cfg = Mock()
        cfg.model = Mock()

        # Create a simple class with dict method instead of using Mock
        class ParamsWithDictMethod:
            def dict(self):
                return {'key1': 'val1', 'key2': 'val2'}

        cfg.model.params = ParamsWithDictMethod()

        result = tmp._snapshot_model_param_keys(cfg)

        assert 'key1' in result
        assert 'key2' in result

    def test_with_params_having_attr_dict(self):
        """Test with params having __dict__ attribute."""
        cfg = Mock()
        cfg.model = Mock()

        class ParamsWithDict:
            def __init__(self):
                self.key1 = 'val1'
                self.key2 = 'val2'

        cfg.model.params = ParamsWithDict()

        result = tmp._snapshot_model_param_keys(cfg)

        assert 'key1' in result
        assert 'key2' in result


# =============================================================================
# Test _coerce_timestamp Edge Cases
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestCoerceTimestampAdvanced:
    """Advanced tests for _coerce_timestamp function."""

    def test_empty_string(self):
        """Test empty string returns None."""
        result = tmp._coerce_timestamp('')
        assert result is None

    def test_none_string(self):
        """Test 'none' string returns None."""
        result = tmp._coerce_timestamp('none')
        assert result is None

    def test_whitespace_string(self):
        """Test whitespace string returns None."""
        result = tmp._coerce_timestamp('   ')
        assert result is None

    def test_milliseconds_heuristic(self):
        """Test large values treated as milliseconds."""
        result = tmp._coerce_timestamp(1704067200000)  # 2024-01-01 in ms

        assert result == 1704067200  # Converted to seconds

    def test_numpy_int(self):
        """Test numpy integer type."""
        import numpy as np
        result = tmp._coerce_timestamp(np.int64(1000))

        assert result == 1000

    def test_numpy_float(self):
        """Test numpy float type."""
        import numpy as np
        result = tmp._coerce_timestamp(np.float64(1000.0))

        assert result == 1000

    def test_nan_float(self):
        """Test NaN float returns None."""
        import numpy as np
        result = tmp._coerce_timestamp(float('nan'))

        assert result is None

    def test_pandas_timestamp_with_tz(self):
        """Test pandas Timestamp with timezone."""
        import pandas as pd
        ts = pd.Timestamp('2024-01-01', tz='US/Eastern')
        result = tmp._coerce_timestamp(ts)

        assert result is not None
        assert isinstance(result, int)


# =============================================================================
# Test Edge Cases for Various Functions
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestMiscEdgeCases:
    """Miscellaneous edge case tests."""

    def test_flatten_candidates_deeply_nested(self):
        """Test _flatten_candidates with deeply nested lists."""
        result = list(tmp._flatten_candidates([[[1, 2], 3], [4, [5, 6]]]))

        assert 1 in result
        assert 6 in result

    def test_value_changed_with_inf(self):
        """Test _value_changed with infinity values."""
        result = tmp._value_changed(float('inf'), float('inf'))

        # Both inf should be considered equal
        assert result is False

    def test_resolve_bar_seconds_dict_access(self):
        """Test _resolve_bar_seconds with dict having bar_interval_seconds."""
        cfg = {'bar_interval_seconds': 3600}
        result = tmp._resolve_bar_seconds(cfg)

        # Should handle dict access
        assert result is None or result == 3600  # Depends on implementation


# =============================================================================
# Test _cfg_get Advanced Cases
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestCfgGetAdvanced:
    """Advanced tests for _cfg_get function."""

    def test_with_callable_get_method(self):
        """Test with object having callable get method."""
        class ConfigWithGet:
            def get(self, key, default=None):
                if key == 'test_key':
                    return 'test_value'
                return default

        cfg = ConfigWithGet()
        result = tmp._cfg_get(cfg, 'test_key')

        assert result == 'test_value'

    def test_with_get_method_type_error(self):
        """Test with get method that raises TypeError."""
        class ConfigWithBadGet:
            def get(self, key):  # Only one argument
                if key == 'test_key':
                    return 'test_value'
                raise KeyError(key)

        cfg = ConfigWithBadGet()
        result = tmp._cfg_get(cfg, 'test_key')

        assert result == 'test_value'

    def test_with_model_dump_method(self):
        """Test with object having model_dump method."""
        class ConfigWithModelDump:
            def model_dump(self):
                return {'key1': 'val1', 'key2': 'val2'}

        cfg = ConfigWithModelDump()
        result = tmp._cfg_get(cfg, 'key1')

        assert result == 'val1'

    def test_with_dict_method(self):
        """Test with object having dict() method."""
        class ConfigWithDict:
            def dict(self):
                return {'key1': 'val1', 'key2': 'val2'}

        cfg = ConfigWithDict()
        result = tmp._cfg_get(cfg, 'key1')

        assert result == 'val1'

    def test_with_dataclass(self):
        """Test with dataclass config."""
        from dataclasses import dataclass

        @dataclass
        class DataclassConfig:
            key1: str = 'val1'
            key2: str = 'val2'

        cfg = DataclassConfig()
        result = tmp._cfg_get(cfg, 'key1')

        assert result == 'val1'


# =============================================================================
# Test _format_interval Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestFormatIntervalAdvanced:
    """Advanced tests for _format_interval function."""

    def test_with_none_values(self):
        """Test with None start/end."""
        result = tmp._format_interval((None, None))

        assert result is not None
        assert 'None' in result  # Should show None for unbounded

    def test_with_partial_none(self):
        """Test with one None value."""
        result = tmp._format_interval((1000, None))

        assert result is not None
        assert 'None' in result  # End is None


# =============================================================================
# Test _phase_bounds Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestPhaseBounds:
    """Tests for _phase_bounds function."""

    def test_with_valid_data(self):
        """Test with valid DataFrames."""
        import pandas as pd

        df1 = pd.DataFrame({'timestamp': [1000, 2000, 3000]})
        df2 = pd.DataFrame({'timestamp': [4000, 5000, 6000]})
        dfs = {'df1': df1, 'df2': df2}

        result = tmp._phase_bounds(dfs, 'timestamp')

        assert result[0] == 1000  # min
        assert result[1] == 6000  # max

    def test_with_empty_dfs(self):
        """Test with empty dfs dict."""
        result = tmp._phase_bounds({}, 'timestamp')

        assert result == (None, None)


# =============================================================================
# Test _fmt_ts Function Advanced
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestFmtTsAdvanced:
    """Advanced tests for _fmt_ts function."""

    def test_large_timestamp(self):
        """Test with large timestamp."""
        result = tmp._fmt_ts(1704067200)  # 2024-01-01

        assert '2024' in result


# =============================================================================
# Test AdversarialCallback Advanced
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestAdversarialCallbackAdvanced:
    """Advanced tests for AdversarialCallback class."""

    def test_resolve_sortino_factor_default(self):
        """Test _resolve_sortino_factor returns default when no env attached."""
        # Use spec to prevent Mock from creating infinite child mocks
        from stable_baselines3.common.vec_env import VecEnv
        mock_env = Mock(spec=VecEnv)
        mock_env.get_attr = Mock(return_value=[None])

        # Mock _annualization_sqrt_from_env to prevent recursion
        with patch.object(tmp, '_annualization_sqrt_from_env', return_value=(1.0, None)):
            callback = tmp.AdversarialCallback(
                eval_env=mock_env,
                eval_freq=100,
                regimes=['normal'],
                regime_duration=10,
            )

            result = callback._resolve_sortino_factor()

            assert result > 0  # Should return some positive value


# =============================================================================
# Test _get_distributional_ppo Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestGetDistributionalPpo:
    """Tests for _get_distributional_ppo function."""

    def test_returns_class(self):
        """Test function returns DistributionalPPO class."""
        result = tmp._get_distributional_ppo()

        assert result is not None
        # Check if it's a class
        assert isinstance(result, type)


# =============================================================================
# Test ResolveAnnSqrt Advanced Cases
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestResolveAnnSqrtAdvanced:
    """Advanced tests for _resolve_ann_sqrt function."""

    def test_with_negative_value(self):
        """Test with negative value returns default."""
        result = tmp._resolve_ann_sqrt(-1.0)

        assert result == tmp._DEFAULT_ANNUALIZATION_SQRT

    def test_with_zero_value(self):
        """Test with zero value returns default."""
        result = tmp._resolve_ann_sqrt(0.0)

        assert result == tmp._DEFAULT_ANNUALIZATION_SQRT


# =============================================================================
# Test NanGuardCallback Advanced
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestNanGuardCallbackAdvanced:
    """Advanced tests for NanGuardCallback class."""

    def test_init_default(self):
        """Test NanGuardCallback initialization with defaults."""
        callback = tmp.NanGuardCallback()

        assert callback.threshold == float("inf")
        assert callback.model is None

    def test_init_with_threshold(self):
        """Test NanGuardCallback initialization with custom threshold."""
        callback = tmp.NanGuardCallback(threshold=100.0, verbose=1)

        assert callback.threshold == 100.0

    def test_on_rollout_end_no_loss(self):
        """Test _on_rollout_end when no loss in locals."""
        callback = tmp.NanGuardCallback()
        callback.locals = {}  # No loss key

        # Setup mock model with no parameters
        mock_model = Mock()
        mock_model.parameters = Mock(return_value=[])
        callback.model = mock_model

        # Should not raise
        callback._on_rollout_end()


# =============================================================================
# Test SortinoPruningCallback Advanced
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestSortinoPruningCallbackAdvanced:
    """Advanced tests for SortinoPruningCallback class."""

    def test_sortino_with_good_performance(self):
        """Test sortino calculation with good returns."""
        returns = np.array([0.01, 0.02, 0.015, 0.005, 0.01])  # All positive

        result = tmp.sortino_ratio(returns)

        # Should be positive for all positive returns
        assert result >= 0


# =============================================================================
# Test _assign_nested Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestAssignNested:
    """Tests for _assign_nested function."""

    def test_single_level_key(self):
        """Test assigning value to single-level key."""
        target = {}
        tmp._assign_nested(target, "key", "value")
        assert target["key"] == "value"

    def test_nested_key(self):
        """Test assigning value to nested key."""
        target = {}
        tmp._assign_nested(target, "level1.level2.key", "value")
        assert target["level1"]["level2"]["key"] == "value"

    def test_empty_key(self):
        """Test with empty key string."""
        target = {}
        tmp._assign_nested(target, "", "value")
        assert target == {}

    def test_overwrite_existing(self):
        """Test overwriting existing value."""
        target = {"key": "old"}
        tmp._assign_nested(target, "key", "new")
        assert target["key"] == "new"

    def test_create_intermediate_dicts(self):
        """Test creating intermediate dicts when needed."""
        target = {"level1": "not_a_dict"}
        tmp._assign_nested(target, "level1.level2", "value")
        assert target["level1"]["level2"] == "value"


# =============================================================================
# Test _wrap_futures_env_if_needed Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestWrapFuturesEnvIfNeeded:
    """Tests for _wrap_futures_env_if_needed function."""

    def test_non_futures_asset_class(self):
        """Test with non-futures asset class returns env unchanged."""
        mock_env = Mock()
        result = tmp._wrap_futures_env_if_needed(
            env=mock_env,
            asset_class="crypto_spot",
            futures_config=None,
        )
        assert result is mock_env

    def test_equity_asset_class(self):
        """Test with equity asset class returns env unchanged."""
        mock_env = Mock()
        result = tmp._wrap_futures_env_if_needed(
            env=mock_env,
            asset_class="equity",
            futures_config=None,
        )
        assert result is mock_env


# =============================================================================
# Test SortinoPruningCallback Class
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestSortinoPruningCallback:
    """Tests for SortinoPruningCallback class."""

    def test_init(self):
        """Test initialization."""
        mock_trial = Mock()
        mock_env = Mock()

        callback = tmp.SortinoPruningCallback(
            trial=mock_trial,
            eval_env=mock_env,
            n_eval_episodes=5,
            eval_freq=1000,
            verbose=1,
        )

        assert callback.trial is mock_trial
        assert callback.eval_env is mock_env
        assert callback.n_eval_episodes == 5
        assert callback.eval_freq == 1000
        assert callback._last_eval_step == 0


# =============================================================================
# Test ObjectiveScorePruningCallback Class
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestObjectiveScorePruningCallback:
    """Tests for ObjectiveScorePruningCallback class."""

    def test_init(self):
        """Test initialization."""
        mock_trial = Mock()
        mock_env = Mock()

        callback = tmp.ObjectiveScorePruningCallback(
            trial=mock_trial,
            eval_env=mock_env,
            eval_freq=40000,
            verbose=0,
        )

        assert callback.trial is mock_trial
        assert callback.eval_env is mock_env
        assert callback.eval_freq == 40000
        assert callback.main_weight == 0.5
        assert callback.choppy_weight == 0.3
        assert callback.trend_weight == 0.2


# =============================================================================
# Test _value_changed Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestValueChangedAdvanced:
    """Advanced tests for _value_changed function."""

    def test_both_none(self):
        """Test when both values are None."""
        result = tmp._value_changed(None, None)
        assert result is False

    def test_old_none_new_value(self):
        """Test when old is None and new has value."""
        result = tmp._value_changed(None, 1.0)
        assert result is True

    def test_old_value_new_none(self):
        """Test when old has value and new is None."""
        result = tmp._value_changed(1.0, None)
        assert result is True

    def test_same_values(self):
        """Test when values are same."""
        result = tmp._value_changed(1.0, 1.0)
        assert result is False

    def test_different_values(self):
        """Test when values are different."""
        result = tmp._value_changed(1.0, 2.0)
        assert result is True


# =============================================================================
# Test _install_torch_intrinsic_stub Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestInstallTorchIntrinsicStub:
    """Tests for _install_torch_intrinsic_stub function."""

    def test_already_installed(self):
        """Test early return when already installed."""
        import sys

        # Temporarily add the module to sys.modules
        original = sys.modules.get("torch.nn.intrinsic")
        try:
            sys.modules["torch.nn.intrinsic"] = Mock()

            # Should return early without error
            tmp._install_torch_intrinsic_stub()

            # Module should still be there
            assert "torch.nn.intrinsic" in sys.modules
        finally:
            # Cleanup
            if original is not None:
                sys.modules["torch.nn.intrinsic"] = original
            elif "torch.nn.intrinsic" in sys.modules:
                del sys.modules["torch.nn.intrinsic"]


# =============================================================================
# Test _log_annualization Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestLogAnnualization:
    """Tests for _log_annualization function."""

    def test_with_bar_seconds_none(self):
        """Test logging when bar_seconds is None."""
        # Just verify it doesn't raise
        tmp._log_annualization("TestLabel", 1.0, None)

    def test_with_bar_seconds_value(self):
        """Test logging when bar_seconds has value."""
        # Just verify it doesn't raise
        tmp._log_annualization("TestLabel", 1.0, 3600.0)


# =============================================================================
# Test _normalize_interval Function Edge Cases
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestNormalizeIntervalEdgeCases:
    """Edge case tests for _normalize_interval function."""

    def test_with_numpy_int(self):
        """Test with numpy integer values."""
        import numpy as np
        result = tmp._normalize_interval((np.int64(1000), np.int64(2000)))
        assert result == (1000, 2000)

    def test_with_numpy_float(self):
        """Test with numpy float values."""
        import numpy as np
        result = tmp._normalize_interval((np.float64(1000.0), np.float64(2000.0)))
        assert result == (1000, 2000)


# =============================================================================
# Test _resolve_bar_seconds Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestResolveBarSecondsAdvanced:
    """Advanced tests for _resolve_bar_seconds function."""

    def test_with_none(self):
        """Test with None source."""
        result = tmp._resolve_bar_seconds(None)
        assert result is None

    def test_with_get_bar_interval_seconds_method(self):
        """Test with object that has get_bar_interval_seconds method."""
        mock_obj = Mock()
        mock_obj.get_bar_interval_seconds = Mock(return_value=3600.0)

        result = tmp._resolve_bar_seconds(mock_obj)

        assert result == 3600.0


# =============================================================================
# Test sortino_ratio Edge Cases
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestSortinoRatioEdgeCases:
    """Edge case tests for sortino_ratio function."""

    def test_empty_returns(self):
        """Test with empty returns array."""
        result = tmp.sortino_ratio(np.array([]))
        assert np.isnan(result) or result == 0.0

    def test_single_return(self):
        """Test with single return."""
        result = tmp.sortino_ratio(np.array([0.01]))
        # With single return, downside_std might be 0
        assert np.isfinite(result) or np.isnan(result)

    def test_all_negative_returns(self):
        """Test with all negative returns."""
        result = tmp.sortino_ratio(np.array([-0.01, -0.02, -0.01]))
        # Negative mean with downside deviation should give negative Sortino
        assert result < 0 or np.isnan(result)

    def test_with_custom_annualization(self):
        """Test with custom annualization factor."""
        returns = np.array([0.01, 0.02, 0.015])
        result = tmp.sortino_ratio(returns, annualization_sqrt=10.0)
        assert np.isfinite(result)


# =============================================================================
# Test sharpe_ratio Edge Cases
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestSharpeRatioEdgeCases:
    """Edge case tests for sharpe_ratio function."""

    def test_constant_returns(self):
        """Test with constant returns (zero std)."""
        result = tmp.sharpe_ratio(np.array([0.01, 0.01, 0.01]))
        # Zero std should handle gracefully
        assert np.isfinite(result) or np.isinf(result) or np.isnan(result)

    def test_with_custom_annualization(self):
        """Test with custom annualization factor."""
        returns = np.array([0.01, 0.02, 0.015])
        result = tmp.sharpe_ratio(returns, annualization_sqrt=10.0)
        assert np.isfinite(result)


# =============================================================================
# Test _annualization_sqrt_from_env Function
# =============================================================================

@pytest.mark.skipif(not MODULE_LOADED, reason="Module not loaded")
class TestAnnualizationSqrtFromEnv:
    """Tests for _annualization_sqrt_from_env function."""

    def test_with_none(self):
        """Test with None source."""
        result = tmp._annualization_sqrt_from_env(None)
        assert result[0] == tmp._DEFAULT_ANNUALIZATION_SQRT
        assert result[1] is None

    def test_with_bar_seconds(self):
        """Test with object that provides bar_seconds."""
        mock_obj = Mock()
        mock_obj.get_bar_interval_seconds = Mock(return_value=3600.0)

        result = tmp._annualization_sqrt_from_env(mock_obj)

        assert result[0] > 0  # Should be a positive sqrt factor
        assert result[1] == 3600.0


# =============================================================================
# Run Tests
# =============================================================================

if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
