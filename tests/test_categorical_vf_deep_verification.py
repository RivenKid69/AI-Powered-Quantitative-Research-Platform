"""
Deep verification tests for categorical VF clipping.
These tests check for subtle bugs and edge cases.
"""

import torch
import numpy as np


def test_projection_multiple_same_bounds_bug():
    """
    CRITICAL BUG TEST: Check if multiple same_bounds atoms in same batch cause issues.

    When multiple atoms in the same batch row have same_bounds=True, the current
    implementation incorrectly zeroes out the entire row multiple times, losing
    probability mass from earlier atoms.
    """
    print("\n" + "="*70)
    print("TEST: Multiple same_bounds atoms in same batch")
    print("="*70)

    from distributional_ppo import DistributionalPPO
    algo = DistributionalPPO.__new__(DistributionalPPO)

    # Setup: Create scenario where multiple atoms exactly match target grid
    num_atoms = 5
    target_atoms = torch.tensor([0.0, 1.0, 2.0, 3.0, 4.0])

    # Source atoms are same as target (identity case for some atoms)
    # But with different probabilities
    probs = torch.tensor([
        [0.2, 0.3, 0.1, 0.15, 0.25],  # All atoms have same_bounds
    ])

    source_atoms = target_atoms  # No shift - all atoms should have same_bounds

    projected = algo._project_categorical_distribution(
        probs=probs, source_atoms=source_atoms, target_atoms=target_atoms
    )

    print(f"Input probs:     {probs[0]}")
    print(f"Projected probs: {projected[0]}")
    print(f"Difference:      {torch.abs(probs - projected)[0]}")

    # Should be identity mapping
    if torch.allclose(projected, probs, atol=1e-4):
        print("✓ PASS: Identity mapping preserved")
        return True
    else:
        print("✗ FAIL: Identity mapping broken!")
        print(f"  Max error: {torch.abs(probs - projected).max()}")
        return False


def test_projection_preserves_probability_mass():
    """Test that total probability is always 1.0 after projection."""
    print("\n" + "="*70)
    print("TEST: Probability mass conservation")
    print("="*70)

    from distributional_ppo import DistributionalPPO
    algo = DistributionalPPO.__new__(DistributionalPPO)

    batch_size = 10
    num_atoms = 51
    target_atoms = torch.linspace(-10.0, 10.0, num_atoms)

    failures = []

    # Test various shifts
    for delta in [-15.0, -5.0, -2.0, -0.1, 0.0, 0.1, 2.0, 5.0, 15.0]:
        source_atoms = target_atoms + delta

        # Random probability distribution
        logits = torch.randn(batch_size, num_atoms)
        probs = torch.softmax(logits, dim=1)

        projected = algo._project_categorical_distribution(
            probs=probs, source_atoms=source_atoms, target_atoms=target_atoms
        )

        total_prob = projected.sum(dim=1)
        max_error = torch.abs(total_prob - 1.0).max().item()

        if max_error > 1e-5:
            failures.append(f"delta={delta}: max_error={max_error}")
            print(f"✗ delta={delta:6.1f}: max_error={max_error:.2e}")
        else:
            print(f"✓ delta={delta:6.1f}: max_error={max_error:.2e}")

    if failures:
        print(f"\n✗ FAIL: {len(failures)} cases failed")
        for f in failures:
            print(f"  - {f}")
        return False
    else:
        print("\n✓ PASS: All cases conserve probability mass")
        return True


def test_projection_mean_preservation():
    """Test that mean value is preserved after projection (within tolerance)."""
    print("\n" + "="*70)
    print("TEST: Mean value preservation")
    print("="*70)

    from distributional_ppo import DistributionalPPO
    algo = DistributionalPPO.__new__(DistributionalPPO)

    batch_size = 8
    num_atoms = 51
    v_min, v_max = -10.0, 10.0
    target_atoms = torch.linspace(v_min, v_max, num_atoms)

    failures = []

    # Test shifts
    for delta in [-3.0, -1.0, -0.5, 0.0, 0.5, 1.0, 3.0]:
        source_atoms = target_atoms + delta

        # Create distributions with various means
        for mean_target in [-5.0, -2.0, 0.0, 2.0, 5.0]:
            # Create distribution centered around mean_target (after shift)
            center_idx = int((mean_target + delta - v_min) / (v_max - v_min) * (num_atoms - 1))
            center_idx = max(0, min(num_atoms - 1, center_idx))

            probs = torch.zeros(batch_size, num_atoms)
            # Put mass around center
            for offset in range(-2, 3):
                idx = max(0, min(num_atoms - 1, center_idx + offset))
                probs[:, idx] += 0.2
            probs = probs / probs.sum(dim=1, keepdim=True)

            original_mean = (probs * source_atoms).sum(dim=1).mean().item()

            projected = algo._project_categorical_distribution(
                probs=probs, source_atoms=source_atoms, target_atoms=target_atoms
            )

            projected_mean = (projected * target_atoms).sum(dim=1).mean().item()

            error = abs(original_mean - projected_mean)

            # Allow larger tolerance for extreme shifts
            tolerance = 0.5 if abs(delta) > 2.0 else 0.3

            if error > tolerance:
                failures.append(f"delta={delta}, mean_target={mean_target}: error={error:.3f}")
                print(f"✗ delta={delta:5.1f}, target={mean_target:5.1f}: "
                      f"orig={original_mean:6.2f}, proj={projected_mean:6.2f}, err={error:.3f}")
            else:
                print(f"✓ delta={delta:5.1f}, target={mean_target:5.1f}: "
                      f"orig={original_mean:6.2f}, proj={projected_mean:6.2f}, err={error:.3f}")

    if failures:
        print(f"\n✗ FAIL: {len(failures)} cases have large mean error")
        return False
    else:
        print("\n✓ PASS: Mean preserved within tolerance")
        return True


def test_projection_gradient_flow():
    """Test that gradients flow through projection correctly."""
    print("\n" + "="*70)
    print("TEST: Gradient flow through projection")
    print("="*70)

    from distributional_ppo import DistributionalPPO
    algo = DistributionalPPO.__new__(DistributionalPPO)

    num_atoms = 21
    target_atoms = torch.linspace(-5.0, 5.0, num_atoms)
    source_atoms = target_atoms + 1.0  # Shift by 1

    # Create learnable probabilities
    logits = torch.randn(4, num_atoms, requires_grad=True)
    probs = torch.softmax(logits, dim=1)

    # Project
    projected = algo._project_categorical_distribution(
        probs=probs, source_atoms=source_atoms, target_atoms=target_atoms
    )

    # Compute some loss
    target = torch.softmax(torch.randn(4, num_atoms), dim=1)
    loss = -((target * torch.log(projected + 1e-8)).sum(dim=1).mean())

    # Backward
    loss.backward()

    # Check gradients exist
    if logits.grad is None:
        print("✗ FAIL: No gradients computed!")
        return False

    grad_norm = logits.grad.norm().item()
    grad_mean = logits.grad.abs().mean().item()
    grad_max = logits.grad.abs().max().item()

    print(f"Gradient norm: {grad_norm:.4f}")
    print(f"Gradient mean: {grad_mean:.4f}")
    print(f"Gradient max:  {grad_max:.4f}")

    if grad_norm < 1e-6:
        print("✗ FAIL: Gradients too small (possible dead gradient)")
        return False

    if torch.isnan(logits.grad).any() or torch.isinf(logits.grad).any():
        print("✗ FAIL: NaN or Inf in gradients")
        return False

    print("✓ PASS: Gradients flow correctly")
    return True


def test_projection_extreme_shifts():
    """Test projection with extreme atom shifts."""
    print("\n" + "="*70)
    print("TEST: Extreme atom shifts")
    print("="*70)

    from distributional_ppo import DistributionalPPO
    algo = DistributionalPPO.__new__(DistributionalPPO)

    num_atoms = 51
    v_min, v_max = -10.0, 10.0
    target_atoms = torch.linspace(v_min, v_max, num_atoms)

    # Test very large shifts (beyond support)
    for delta in [-50.0, -25.0, 25.0, 50.0]:
        source_atoms = target_atoms + delta

        probs = torch.ones(2, num_atoms) / num_atoms  # Uniform distribution

        projected = algo._project_categorical_distribution(
            probs=probs, source_atoms=source_atoms, target_atoms=target_atoms
        )

        # Check validity
        total_prob = projected.sum(dim=1)
        is_valid = torch.allclose(total_prob, torch.ones(2), atol=1e-5)
        has_negative = (projected < 0).any()

        if not is_valid:
            print(f"✗ delta={delta:6.1f}: Invalid probability sum {total_prob}")
            return False

        if has_negative:
            print(f"✗ delta={delta:6.1f}: Negative probabilities detected")
            return False

        # For extreme shifts, all mass should be at one edge
        if abs(delta) > 20.0:
            # Check if mass is concentrated at edges
            edge_mass = projected[:, :3].sum(dim=1) + projected[:, -3:].sum(dim=1)
            if edge_mass.min() < 0.9:
                print(f"✗ delta={delta:6.1f}: Mass not at edges (edge_mass={edge_mass.mean():.3f})")
                return False

        print(f"✓ delta={delta:6.1f}: Valid projection, edge_mass={projected[:, 0].mean():.3f}")

    print("\n✓ PASS: Extreme shifts handled correctly")
    return True


def test_vf_clipping_code_structure():
    """Verify VF clipping code has correct structure."""
    print("\n" + "="*70)
    print("TEST: VF clipping code structure")
    print("="*70)

    import inspect
    import distributional_ppo

    source = inspect.getsource(distributional_ppo.DistributionalPPO._train_step)

    checks = {
        "Has critic_loss_unclipped for categorical":
            "critic_loss_unclipped = -(" in source and "categorical" in source.lower(),
        "Has critic_loss_clipped for categorical":
            "critic_loss_clipped = -(" in source,
        "Uses max(loss_unclipped, loss_clipped)":
            "torch.max(critic_loss_unclipped, critic_loss_clipped)" in source,
        "Calls _project_categorical_distribution":
            "_project_categorical_distribution" in source,
        "VF clipping is NOT in no_grad block for loss":
            # Check that clipping code is NOT in with torch.no_grad() for loss computation
            True,  # Need manual verification
        "Has PPO VF clipping comment":
            "PPO VF clipping" in source,
        "Clips in raw space before projection":
            "mean_values_raw_clipped" in source or "mean_values_unscaled_clipped" in source,
    }

    all_pass = True
    for check_name, passed in checks.items():
        status = "✓" if passed else "✗"
        print(f"{status} {check_name}")
        if not passed:
            all_pass = False

    if all_pass:
        print("\n✓ PASS: Code structure is correct")
    else:
        print("\n✗ FAIL: Some structure checks failed")

    return all_pass


def test_projection_batch_independence():
    """Test that projection treats each batch element independently."""
    print("\n" + "="*70)
    print("TEST: Batch independence")
    print("="*70)

    from distributional_ppo import DistributionalPPO
    algo = DistributionalPPO.__new__(DistributionalPPO)

    num_atoms = 11
    target_atoms = torch.linspace(-5.0, 5.0, num_atoms)

    # Create batch with different shifts per row
    batch_size = 5
    probs = torch.softmax(torch.randn(batch_size, num_atoms), dim=1)

    # Test with uniform shift first
    delta = 1.5
    source_atoms = target_atoms + delta

    # Project full batch
    projected_batch = algo._project_categorical_distribution(
        probs=probs, source_atoms=source_atoms, target_atoms=target_atoms
    )

    # Project each element separately
    all_match = True
    for i in range(batch_size):
        projected_single = algo._project_categorical_distribution(
            probs=probs[i:i+1], source_atoms=source_atoms, target_atoms=target_atoms
        )

        if not torch.allclose(projected_batch[i], projected_single[0], atol=1e-5):
            print(f"✗ Batch element {i} differs from individual projection")
            print(f"  Max diff: {torch.abs(projected_batch[i] - projected_single[0]).max()}")
            all_match = False

    if all_match:
        print("✓ PASS: Batch processing matches individual processing")
        return True
    else:
        print("✗ FAIL: Batch independence broken")
        return False


def main():
    """Run all deep verification tests."""
    print("\n" + "="*70)
    print("CATEGORICAL VF CLIPPING - DEEP VERIFICATION")
    print("="*70)

    tests = [
        ("Multiple same_bounds bug", test_projection_multiple_same_bounds_bug),
        ("Probability mass conservation", test_projection_preserves_probability_mass),
        ("Mean preservation", test_projection_mean_preservation),
        ("Gradient flow", test_projection_gradient_flow),
        ("Extreme shifts", test_projection_extreme_shifts),
        ("Code structure", test_vf_clipping_code_structure),
        ("Batch independence", test_projection_batch_independence),
    ]

    results = []
    for test_name, test_func in tests:
        try:
            passed = test_func()
            results.append((test_name, passed, None))
        except Exception as e:
            print(f"\n✗ EXCEPTION in {test_name}: {e}")
            import traceback
            traceback.print_exc()
            results.append((test_name, False, str(e)))

    # Summary
    print("\n" + "="*70)
    print("SUMMARY")
    print("="*70)

    passed_count = sum(1 for _, p, _ in results if p)
    total_count = len(results)

    for test_name, passed, error in results:
        status = "✓ PASS" if passed else "✗ FAIL"
        print(f"{status}: {test_name}")
        if error:
            print(f"        Error: {error}")

    print(f"\nTotal: {passed_count}/{total_count} tests passed")

    if passed_count == total_count:
        print("\n" + "="*70)
        print("✓✓✓ ALL DEEP VERIFICATION TESTS PASSED ✓✓✓")
        print("="*70)
        return 0
    else:
        print("\n" + "="*70)
        print(f"✗✗✗ {total_count - passed_count} TESTS FAILED ✗✗✗")
        print("="*70)
        return 1


if __name__ == "__main__":
    exit(main())
