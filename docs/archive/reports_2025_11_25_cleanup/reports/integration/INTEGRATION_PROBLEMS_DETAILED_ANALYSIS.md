# –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ UPGD/PBT/Twin Critics/VGS

**–î–∞—Ç–∞:** 2025-11-20
**–°—Ç–∞—Ç—É—Å:** –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω
**–ú–µ—Ç–æ–¥:** –°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–æ–≤–æ–π –±–∞–∑—ã + review –ª—É—á—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫

---

## Executive Summary

–ü—Ä–æ–≤–µ–¥–µ–Ω –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ 4 —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π:
1. **UPGD Optimizer** (Utility-based Perturbed Gradient Descent)
2. **PBT** (Population-Based Training)
3. **Twin Critics** (Adversarial)
4. **VGS** (Variance Gradient Scaling)

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
- ‚úÖ –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Å—Ç—ã: **24/24 PASSED** (100%)
- ‚ö†Ô∏è **7 –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º** –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã
- üî¥ **2 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö**, üü° **3 –≤—ã—Å–æ–∫–∏—Ö**, üü¢ **2 –Ω–∏–∑–∫–∏—Ö** –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞

---

## –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

### üî¥ –ü–†–û–ë–õ–ï–ú–ê #1: torch.load() –±–µ–∑ weights_only (–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø)

**–°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å:** üî¥ CRITICAL
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** Security & Safety
**–ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ —Ñ–∞–π–ª—ã:** 10+ —Ñ–∞–π–ª–æ–≤

#### –û–ø–∏—Å–∞–Ω–∏–µ

–ú–Ω–æ–∂–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É—é—Ç `torch.load()` –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ `weights_only=True`, —á—Ç–æ —Å–æ–∑–¥–∞–µ—Ç —É—è–∑–≤–∏–º–æ—Å—Ç—å –¥–ª—è arbitrary code execution —á–µ—Ä–µ–∑ malicious pickle data.

#### –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–ª—É—á–∞–∏

1. **`adversarial/pbt_scheduler.py:274`**
   ```python
   new_state_dict = torch.load(source_member.checkpoint_path)
   ```

2. **`infer_signals.py:35`**
   ```python
   model = torch.load(path, map_location="cpu")
   ```

3. **–¢–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã (10+ —Å–ª—É—á–∞–µ–≤):**
   - `tests/test_pbt_adversarial_deep_validation.py:420`
   - `tests/test_pbt_adversarial_real_integration.py:309`
   - `tests/test_twin_critics_feature_integration.py:278,318`
   - –ò –¥—Ä—É–≥–∏–µ...

#### –ü–æ—á–µ–º—É —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞

1. **Security Risk:** Malicious checkpoint –º–æ–∂–µ—Ç –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –∫–æ–¥
2. **Production Risk:** –ü—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ checkpoint –∏–∑ –Ω–µ–Ω–∞–¥–µ–∂–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
3. **PyTorch Warning:** –í –±—É–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏ `weights_only` –±—É–¥–µ—Ç `True` –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

#### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

```python
# BEFORE (–Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω–æ):
new_state_dict = torch.load(source_member.checkpoint_path)

# AFTER (–±–µ–∑–æ–ø–∞—Å–Ω–æ):
new_state_dict = torch.load(
    source_member.checkpoint_path,
    map_location="cpu",  # –¢–∞–∫–∂–µ –ª—É—á—à–µ —É–∫–∞–∑–∞—Ç—å device
    weights_only=True    # –¢–æ–ª—å–∫–æ —Ç–µ–Ω–∑–æ—Ä—ã, –±–µ–∑ arbitrary objects
)
```

#### Impact

- **Training:** –°—Ä–µ–¥–Ω–∏–π (checkpoints –æ—Ç PBT –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å trusted)
- **Production:** –í—ã—Å–æ–∫–∏–π (–µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è external checkpoints)
- **Testing:** –ù–∏–∑–∫–∏–π (—Ç–µ—Å—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ checkpoints)

---

### üî¥ –ü–†–û–ë–õ–ï–ú–ê #2: Pydantic V1 Deprecation Warnings (–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –¥–ª—è –±—É–¥—É—â–µ–≥–æ)

**–°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å:** üî¥ CRITICAL (breaking change –≤ Pydantic V3)
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** Code Quality & Future Compatibility
**–ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ —Ñ–∞–π–ª—ã:** `core_config.py`

#### –û–ø–∏—Å–∞–Ω–∏–µ

`core_config.py` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ Pydantic V1 style decorators (`@root_validator`, `@validator`), –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –≤ Pydantic V3.

#### –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–ª—É—á–∞–∏

```python
# core_config.py:755
@root_validator(pre=True)
def validate_xxx(cls, values):
    ...

# core_config.py:1066, 1124, 1195 - –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏
```

#### –ü–æ—á–µ–º—É —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞

1. **Breaking Change:** Pydantic V3 —É–¥–∞–ª–∏—Ç —ç—Ç–∏ decorators
2. **Warnings Flood:** 10+ warnings –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∑–∞–ø—É—Å–∫–µ —Ç–µ—Å—Ç–æ–≤
3. **Maintenance:** –£—Å–ª–æ–∂–Ω—è–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ dependencies

#### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

```python
# BEFORE (V1 style):
@root_validator(pre=True)
def validate_xxx(cls, values):
    return values

# AFTER (V2 style):
from pydantic import model_validator

@model_validator(mode='before')
@classmethod
def validate_xxx(cls, values):
    return values
```

#### Impact

- **Training:** –ù–µ—Ç (—Ç–æ–ª—å–∫–æ warnings)
- **Production:** –ù–µ—Ç (–ø–æ–∫–∞ Pydantic V2)
- **Future:** –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π (–ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –Ω–∞ Pydantic V3)

---

### üü° –ü–†–û–ë–õ–ï–ú–ê #3: VGS + PBT Checkpoint Compatibility (–í–´–°–û–ö–ê–Ø)

**–°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å:** üü° HIGH
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** Integration & State Management
**–ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:** VGS, PBT

#### –û–ø–∏—Å–∞–Ω–∏–µ

–ü—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ VGS —Å PBT, checkpoint exploitation –º–æ–∂–µ—Ç –Ω–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å VGS state. PBTScheduler –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ–ª—å–∫–æ model state_dict, –Ω–æ –Ω–µ VGS state.

#### –ü—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–¥

**File:** `adversarial/pbt_scheduler.py:274-276`
```python
# PBT exploit: load checkpoint from better performer
new_state_dict = torch.load(source_member.checkpoint_path)
member.hyperparams = copy.deepcopy(source_member.hyperparams)
# ‚ùå VGS state –ù–ï –ö–û–ü–ò–†–£–ï–¢–°–Ø!
```

**File:** `distributional_ppo.py:6152-6170` (Bug #10 fix)
```python
# VGS state restore —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–∏ DistributionalPPO.load()
# –ù–æ PBT –¥–µ–ª–∞–µ—Ç –ø—Ä—è–º–æ–π torch.load() checkpoint_path
```

#### –ü–æ—á–µ–º—É —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞

1. **State Mismatch:** VGS member A –∫–æ–ø–∏—Ä—É–µ—Ç policy –æ—Ç member B, –Ω–æ VGS statistics –æ—Å—Ç–∞—é—Ç—Å—è –æ—Ç A
2. **Training Instability:** VGS stats (grad_mean_ema, grad_var_ema) –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –Ω–æ–≤–æ–π policy
3. **Suboptimal Scaling:** VGS –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞—Ä—ã–µ statistics –¥–ª—è –Ω–æ–≤–æ–π policy

#### –°—Ü–µ–Ω–∞—Ä–∏–π

```
1. Member A: VGS stats = {step_count=500, grad_var_ema=0.1}
2. Member B: VGS stats = {step_count=500, grad_var_ema=0.01} (better performer)
3. PBT exploit: Member A copies policy from B
4. ‚ùå Member A now has:
   - Policy from B (good)
   - VGS stats from A (WRONG - should be from B)
5. Result: VGS applies incorrect scaling to new policy
```

#### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

**Option 1:** Include VGS state in checkpoint (preferred)
```python
# In DistributionalPPO._save_checkpoint_for_pbt()
checkpoint = {
    "model_state_dict": self.policy.state_dict(),
    "optimizer_state_dict": self.policy.optimizer.state_dict(),
    "vgs_state_dict": self._variance_gradient_scaler.state_dict() if self._variance_gradient_scaler else None,
}
torch.save(checkpoint, checkpoint_path, weights_only=True)
```

**Option 2:** Reset VGS stats after PBT exploit
```python
# In PBTScheduler.exploit_and_explore()
if new_state_dict is not None:
    # Reset VGS statistics to avoid mismatch
    # (VGS –±—É–¥–µ—Ç relearn statistics –¥–ª—è –Ω–æ–≤–æ–π policy)
    model._variance_gradient_scaler.reset_statistics()
```

#### Impact

- **Training Correctness:** –°—Ä–µ–¥–Ω–∏–π (VGS –±—É–¥–µ—Ç relearn –∑–∞ ~100 steps warmup)
- **Training Efficiency:** –í—ã—Å–æ–∫–∏–π (–Ω–µ–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π scaling –≤ —Ç–µ—á–µ–Ω–∏–µ warmup)
- **PBT Performance:** –í—ã—Å–æ–∫–∏–π (–º–æ–∂–µ—Ç —Å–Ω–∏–∑–∏—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å exploitation)

---

### üü° –ü–†–û–ë–õ–ï–ú–ê #4: UPGD Perturbation Noise + VGS Scaling Interaction (–í–´–°–û–ö–ê–Ø)

**–°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å:** üü° HIGH
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** Numerical Behavior & Algorithm Interaction
**–ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:** UPGD, VGS

#### –û–ø–∏—Å–∞–Ω–∏–µ

UPGD –¥–æ–±–∞–≤–ª—è–µ—Ç perturbation noise –∫ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º –¥–ª—è plasticity, –∞ VGS –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ variance. –≠—Ç–∏ –¥–≤–∞ –º–µ—Ö–∞–Ω–∏–∑–º–∞ –º–æ–≥—É—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞—Ç—å.

#### –ü—Ä–æ–±–ª–µ–º–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω

**UPGD (`optimizers/adaptive_upgd.py:162,175`):**
```python
# Add perturbation noise
noise = torch.randn_like(p.grad) * group["sigma"]

# Update with noise
perturbed_update = (adaptive_grad + noise) * (1 - scaled_utility)
```

**VGS (`variance_gradient_scaler.py:282-284`):**
```python
# Scale gradients based on variance
if scaling_factor < 1.0:
    param.grad.data.mul_(scaling_factor)
```

**Execution order –≤ DistributionalPPO:**
```python
loss.backward()                          # 1. Compute gradients
vgs.scale_gradients()                    # 2. VGS scales DOWN
optimizer.step()                         # 3. UPGD adds noise and updates
vgs.step()                               # 4. VGS updates statistics
```

#### –ü–æ—á–µ–º—É —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞

1. **VGS observes pre-noise gradients:** VGS –≤—ã—á–∏—Å–ª—è–µ—Ç variance –Ω–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞—Ö –ë–ï–ó UPGD noise
2. **UPGD adds noise AFTER VGS scaling:** Noise –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —É–∂–µ –ü–û–°–õ–ï VGS scaling
3. **Statistics Mismatch:** VGS statistics –Ω–µ —É—á–∏—Ç—ã–≤–∞—é—Ç UPGD noise contribution

#### –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã

1. **Underestimated Variance:** VGS –º–æ–∂–µ—Ç –Ω–µ–¥–æ–æ—Ü–µ–Ω–∏–≤–∞—Ç—å actual variance (—Ç.–∫. –Ω–µ –≤–∏–¥–∏—Ç UPGD noise)
2. **Overcorrection:** VGS –º–æ–∂–µ—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å —Å–ª–∏—à–∫–æ–º —Å–∏–ª—å–Ω—ã–π scaling
3. **Noise Amplification:** Scaled gradients + noise –º–æ–≥—É—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å

#### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

**Option 1:** Adjust VGS to account for UPGD noise (complex)
```python
# In VGS, adjust variance estimate if UPGD is used
effective_variance = observed_variance + sigma^2  # sigma from UPGD
```

**Option 2:** Apply VGS AFTER optimizer (simpler, –Ω–æ –Ω–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ)
```python
# Change execution order
loss.backward()
optimizer.step()  # UPGD adds noise here
vgs.scale_gradients()  # Scale AFTER noise
vgs.step()
```

**Option 3:** Disable VGS scaling during UPGD perturbation (conservative)
```python
# In VGS config for UPGD runs
vgs_alpha = 0.05  # Reduce scaling strength (default: 0.1)
vgs_warmup_steps = 200  # Longer warmup (default: 100)
```

#### Impact

- **Training Stability:** –°—Ä–µ–¥–Ω–∏–π (–º–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å –Ω–µ–±–æ–ª—å—à—É—é –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å)
- **Convergence Speed:** –ù–∏–∑–∫–∏–π (–æ–±–∞ –º–µ—Ö–∞–Ω–∏–∑–º–∞ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É—é—Ç training)
- **Hyperparameter Sensitivity:** –í—ã—Å–æ–∫–∏–π (—Ç—Ä–µ–±—É–µ—Ç —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏)

---

### üü° –ü–†–û–ë–õ–ï–ú–ê #5: Twin Critics + PBT Hyperparameter Mutation (–°–†–ï–î–ù–Ø–Ø)

**–°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å:** üü° MEDIUM
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** Hyperparameter Compatibility
**–ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:** Twin Critics, PBT

#### –û–ø–∏—Å–∞–Ω–∏–µ

PBT –º–æ–∂–µ—Ç –º—É—Ç–∏—Ä–æ–≤–∞—Ç—å hyperparameters (–Ω–∞–ø—Ä–∏–º–µ—Ä, `clip_range`, `entropy_coef`), –Ω–æ –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç, —á—Ç–æ Twin Critics —Ç—Ä–µ–±—É—é—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ–±–æ–∏—Ö critic networks.

#### –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞

**–ï—Å–ª–∏ PBT –º—É—Ç–∏—Ä—É–µ—Ç critic-related hyperparameters:**
- `vf_coef` (value function coefficient)
- `learning_rate` (–≤–ª–∏—è–µ—Ç –Ω–∞ –æ–±–µ critics)
- Distributional parameters (`num_atoms`, `v_min`, `v_max`)

**Twin Critics –º–æ–∂–µ—Ç —Ä–µ–∞–≥–∏—Ä–æ–≤–∞—Ç—å –ø–æ-—Ä–∞–∑–Ω–æ–º—É:**
- Critic 1 –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª–µ–µ/–º–µ–Ω–µ–µ conservative
- Asymmetric learning rates –º–µ–∂–¥—É critics
- Divergence –º–µ–∂–¥—É twin estimates

#### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è

–õ–∏–±–æ:
1. **Exclude critic hyperparameters from PBT mutation**
2. **Monitor twin critics divergence** –∏ –¥–æ–±–∞–≤–∏—Ç—å constraint

---

### üü¢ –ü–†–û–ë–õ–ï–ú–ê #6: Missing Integration Tests –¥–ª—è PBT + All Components (–ù–ò–ó–ö–ê–Ø)

**–°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å:** üü¢ LOW
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** Test Coverage

#### –û–ø–∏—Å–∞–Ω–∏–µ

–ï—Å—Ç—å —Ç–µ—Å—Ç—ã –¥–ª—è:
- ‚úÖ UPGD + VGS
- ‚úÖ UPGD + Twin Critics
- ‚úÖ UPGD + PBT
- ‚úÖ All 4 components (basic)

**–ù–æ –ù–ï–¢ —Ç–µ—Å—Ç–æ–≤ –¥–ª—è:**
- ‚ùå PBT + Twin Critics + VGS (–±–µ–∑ UPGD)
- ‚ùå PBT exploitation —Å VGS state transfer
- ‚ùå PBT + Twin Critics divergence monitoring

---

### üü¢ –ü–†–û–ë–õ–ï–ú–ê #7: VGS Warmup + PBT Early Exploitation (–ù–ò–ó–ö–ê–Ø)

**–°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å:** üü¢ LOW
**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** Training Dynamics

#### –û–ø–∏—Å–∞–Ω–∏–µ

VGS –∏–º–µ–µ—Ç warmup period (default: 100 steps), –Ω–æ PBT –º–æ–∂–µ—Ç –¥–µ–ª–∞—Ç—å exploitation —Ä–∞–Ω—å—à–µ (default: `perturbation_interval=5` training updates).

**–ï—Å–ª–∏ PBT exploit –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –î–û VGS warmup –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:**
- VGS statistics –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–º–∏
- Copied VGS state –º–æ–∂–µ—Ç –±—ã—Ç—å immature

#### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è

Ensure `pbt.perturbation_interval * update_batch_size > vgs.warmup_steps`

---

## –ü—Ä–∏–æ—Ä–∏—Ç–µ–∑–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ (–Ω–µ–º–µ–¥–ª–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è)

1. **–ü–†–û–ë–õ–ï–ú–ê #1: torch.load() security** ‚Üí –ù—É–∂–µ–Ω FIX
2. **–ü–†–û–ë–õ–ï–ú–ê #2: Pydantic deprecation** ‚Üí –ù—É–∂–µ–Ω FIX (–¥–æ Pydantic V3)

### –í—ã—Å–æ–∫–∏–µ (–≤–∞–∂–Ω—ã–µ –¥–ª—è production)

3. **–ü–†–û–ë–õ–ï–ú–ê #3: VGS + PBT state mismatch** ‚Üí –ù—É–∂–µ–Ω TEST + –≤–æ–∑–º–æ–∂–Ω–æ FIX
4. **–ü–†–û–ë–õ–ï–ú–ê #4: UPGD noise + VGS scaling** ‚Üí –ù—É–∂–µ–Ω TEST + –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –°—Ä–µ–¥–Ω–∏–µ (–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å)

5. **–ü–†–û–ë–õ–ï–ú–ê #5: Twin Critics + PBT mutations** ‚Üí –ù—É–∂–µ–Ω –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –ù–∏–∑–∫–∏–µ (non-blocking)

6. **–ü–†–û–ë–õ–ï–ú–ê #6: Test coverage gaps** ‚Üí Nice to have
7. **–ü–†–û–ë–õ–ï–ú–ê #7: VGS warmup timing** ‚Üí Config recommendation

---

## –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π

### Phase 1: Critical Fixes (–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ)

1. ‚úÖ **FIX torch.load() security**
   - Update `adversarial/pbt_scheduler.py`
   - Update `infer_signals.py`
   - Update test files (low priority)

2. ‚úÖ **FIX Pydantic deprecation**
   - Migrate `core_config.py` to V2 style validators

### Phase 2: Integration Testing (–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥)

3. ‚úÖ **TEST VGS + PBT state transfer**
   - Create `test_vgs_pbt_checkpoint_compatibility.py`
   - Verify VGS state is correctly handled during PBT exploit

4. ‚úÖ **TEST UPGD noise + VGS scaling**
   - Create `test_upgd_vgs_noise_interaction.py`
   - Monitor variance estimates and training stability

### Phase 3: Monitoring & Validation (Production)

5. ‚úÖ **Monitor Twin Critics divergence** in PBT runs
6. ‚úÖ **Validate configuration** (VGS warmup vs PBT interval)

---

## –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º

| –ü—Ä–æ–±–ª–µ–º–∞ | –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å | Severity if occurs | Priority |
|----------|-------------|-------------------|----------|
| #1 torch.load | üî¥ High (–µ—Å–ª–∏ external checkpoints) | üî¥ Critical | P0 |
| #2 Pydantic | üü¢ Low (—Å–µ–π—á–∞—Å), üî¥ High (V3) | üî¥ Critical | P0 |
| #3 VGS+PBT state | üü° Medium | üü° Medium | P1 |
| #4 UPGD+VGS noise | üü¢ Low | üü° Medium | P1 |
| #5 Critics+PBT | üü¢ Low | üü¢ Low | P2 |
| #6 Test coverage | N/A | N/A | P3 |
| #7 Warmup timing | üü¢ Low | üü¢ Low | P3 |

---

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

**–°—Ç–∞—Ç—É—Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏:** ‚úÖ **–†–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤**

**–ë–ª–æ–∫–µ—Ä—ã:** –ù–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –±–ª–æ–∫–µ—Ä–æ–≤ –¥–ª—è production
**Risks:** 2 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º—ã —Ç—Ä–µ–±—É—é—Ç —Ñ–∏–∫—Å–∞ –¥–æ wide deployment

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**
1. ‚úÖ –ò—Å–ø—Ä–∞–≤–∏—Ç—å –ü–†–û–ë–õ–ï–ú–´ #1 –∏ #2 (security & future compatibility)
2. ‚úÖ –°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç—ã –¥–ª—è –ü–†–û–ë–õ–ï–ú #3 –∏ #4 (–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å/–æ–ø—Ä–æ–≤–µ—Ä–≥–Ω—É—Ç—å)
3. ‚úÖ –ï—Å–ª–∏ —Ç–µ—Å—Ç—ã –ø–æ–∫–∞–∂—É—Ç –ø—Ä–æ–±–ª–µ–º—ã ‚Üí –∏—Å–ø—Ä–∞–≤–∏—Ç—å
4. ‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –ü–†–û–ë–õ–ï–ú–´ #5-7 –≤ production

---

**–û—Ç—á–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω:** 2025-11-20
**–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è:** Systematic code review + best practices analysis
**–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:** –°–æ–∑–¥–∞–Ω–∏–µ specialized tests –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –ü–†–û–ë–õ–ï–ú #3 –∏ #4
