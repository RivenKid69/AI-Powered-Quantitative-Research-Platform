# –ü–û–õ–ù–´–ô –°–ü–ò–°–û–ö –í–°–ï–• –ù–ê–ô–î–ï–ù–ù–´–• –ü–†–û–ë–õ–ï–ú
## –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞—É–¥–∏—Ç AI-Powered Quantitative Research Platform

**–î–∞—Ç–∞:** 2025-11-20
**–í—Å–µ–≥–æ –ø—Ä–æ–±–ª–µ–º:** 36 (3 CRITICAL, 5 HIGH, 14 MEDIUM, 14 LOW)

---

# üî¥ CRITICAL ISSUES (3)

## CRITICAL #1: Temporal Causality Violation in Data Degradation

**–§–∞–π–ª:** [impl_offline_data.py:132-140](impl_offline_data.py#L132-L140)
**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** Data Loading Pipeline
**Severity:** üî¥ CRITICAL

### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
–ü—Ä–∏ —Å–∏–º—É–ª—è—Ü–∏–∏ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö (stale) –¥–∞–Ω–Ω—ã—Ö, –∫–æ–¥ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–π –±–∞—Ä (`prev_bar`) —Å –µ–≥–æ **–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º timestamp**, –∞ –Ω–µ —Å —Ç–µ–∫—É—â–∏–º –≤—Ä–µ–º–µ–Ω–µ–º. –≠—Ç–æ —Å–æ–∑–¥–∞–µ—Ç —Ç–µ–º–ø–æ—Ä–∞–ª—å–Ω–æ–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ, –≥–¥–µ –º–æ–¥–µ–ª—å –Ω–∞–±–ª—é–¥–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Ä–µ–º–µ–Ω–∏ `t-1`, –¥—É–º–∞—è —á—Ç–æ —Å–µ–π—á–∞—Å –≤—Ä–µ–º—è `t`.

### –¢–µ–∫—É—â–∏–π –∫–æ–¥:
```python
if prev_bar is not None and self._rng.random() < self._degradation.stale_prob:
    stale_cnt += 1
    if self._rng.random() < self._degradation.dropout_prob:
        delay_ms = self._rng.randint(0, self._degradation.max_delay_ms)
        if delay_ms > 0:
            delay_cnt += 1
            time.sleep(delay_ms / 1000.0)
    yield prev_bar  # ‚Üê –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–∞—Ä —Å–æ –°–¢–ê–†–´–ú timestamp!
    continue
```

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–ª–∏—è–Ω–∏–µ:
- –ù–∞—Ä—É—à–∞–µ—Ç –ø—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—É—é —Å–≤—è–∑—å: –¥–∞–Ω–Ω—ã–µ —Å timestamp `t-1` –¥–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è –≤ –º–æ–º–µ–Ω—Ç `t-1`, –∞ –Ω–µ –≤ –º–æ–º–µ–Ω—Ç `t`
- –í —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–µ —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏—Ö–æ–¥—è—Ç **–≤ —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç** —Å –ø–æ–º–µ—Ç–∫–æ–π –æ –∑–∞–¥–µ—Ä–∂–∫–µ
- –ú–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –Ω–∞ —Ç–µ–º–ø–æ—Ä–∞–ª—å–Ω–æ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –ü—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –Ω–∞ live trading –≤–æ–∑–Ω–∏–∫–Ω–µ—Ç distribution shift

### –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ:
```python
if prev_bar is not None and self._rng.random() < self._degradation.stale_prob:
    stale_cnt += 1
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –±–∞—Ä —Å –¢–ï–ö–£–©–ò–ú timestamp, –Ω–æ –°–¢–ê–†–´–ú–ò –¥–∞–Ω–Ω—ã–º–∏
    stale_bar = Bar(
        ts=ts,  # –¢–ï–ö–£–©–ò–ô timestamp, –Ω–µ prev_bar.ts!
        symbol=prev_bar.symbol,
        open=prev_bar.open,
        high=prev_bar.high,
        low=prev_bar.low,
        close=prev_bar.close,
        volume_base=prev_bar.volume_base,
        trades=prev_bar.trades,
        taker_buy_base=prev_bar.taker_buy_base,
        is_final=True,
        is_stale=True,  # –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    )

    if self._rng.random() < self._degradation.dropout_prob:
        delay_ms = self._rng.randint(0, self._degradation.max_delay_ms)
        if delay_ms > 0:
            delay_cnt += 1
            time.sleep(delay_ms / 1000.0)

    yield stale_bar
    continue
```

### Impact Score: 9/10
**–ü–æ—á–µ–º—É –∫—Ä–∏—Ç–∏—á–Ω–æ:**
- –§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Ç–µ–º–ø–æ—Ä–∞–ª—å–Ω–æ–π –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏
- –í–ª–∏—è–µ—Ç –Ω–∞ –≤—Å–µ –æ–±—É—á–µ–Ω–∏–µ —Å –≤–∫–ª—é—á–µ–Ω–Ω–æ–π –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–µ–π –¥–∞–Ω–Ω—ã—Ö
- –°–æ–∑–¥–∞–µ—Ç –Ω–µ–≤–∏–¥–∏–º—ã–π bias –≤ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö
- –ë—É–¥–µ—Ç –ø—Ä–æ—è–≤–ª—è—Ç—å—Å—è –∫–∞–∫ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –Ω–∞ live

---

## CRITICAL #2: Cross-Symbol Contamination in Normalization

**–§–∞–π–ª:** [features_pipeline.py:160-164](features_pipeline.py#L160-L164)
**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** Feature Pipeline
**Severity:** üî¥ CRITICAL

### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
–ü—Ä–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ, –∫–æ–¥ —Å–Ω–∞—á–∞–ª–∞ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤, –∞ **–∑–∞—Ç–µ–º** –ø—Ä–∏–º–µ–Ω—è–µ—Ç `shift(1)` –∫ –∫–æ–ª–æ–Ω–∫–µ `close`. –≠—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ —Ç–æ–º—É, —á—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ Symbol1 "—É—Ç–µ–∫–∞–µ—Ç" –≤ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É Symbol2.

### –¢–µ–∫—É—â–∏–π –∫–æ–¥:
```python
# –ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤ –æ–¥–∏–Ω DataFrame
big = pd.concat(frames, axis=0, ignore_index=True)

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ shift –∫–æ –í–°–ï–ú–£ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É
if "close_orig" in big.columns:
    pass
elif "close" in big.columns:
    big["close"] = big["close"].shift(1)  # ‚Üê –£–¢–ï–ß–ö–ê –ú–ï–ñ–î–£ –°–ò–ú–í–û–õ–ê–ú–ò!
```

### –ü—Ä–∏–º–µ—Ä –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏—è:
```
–î–æ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏:
BTCUSDT: [100, 101, 102]
ETHUSDT: [200, 201, 202]

–ü–æ—Å–ª–µ concat:
Combined: [100, 101, 102, 200, 201, 202]

–ü–æ—Å–ª–µ shift(1):
Combined: [NaN, 100, 101, 102, 200, 201]
                          ‚Üë
                   –ü–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ BTC (102) —Å—Ç–∞–ª–æ
                   –ø–µ—Ä–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –≤ —Å–µ–∫—Ü–∏–∏ ETH!

BTCUSDT normalized: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è mean/std –≤–∫–ª—é—á–∞—è 102
ETHUSDT normalized: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è mean/std –≤–∫–ª—é—á–∞—è 102
```

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–ª–∏—è–Ω–∏–µ:
- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (mean, std) –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –Ω–∞ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –î–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã —Å–∏–º–≤–æ–ª–æ–≤ —Å–æ–∑–¥–∞–µ—Ç—Å—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç: –∑–Ω–∞—á–µ–Ω–∏–µ Symbol1[n-1] –ø–æ–ø–∞–¥–∞–µ—Ç –≤ Symbol2[0]
- –í—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É—é—Ç—Å—è —Å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞–º–∏
- –ú–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –Ω–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

### –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ:
```python
# –ü—Ä–∏–º–µ–Ω–∏—Ç—å shift –∫ –ö–ê–ñ–î–û–ú–£ —Å–∏–º–≤–æ–ª—É –û–¢–î–ï–õ–¨–ù–û –ø–µ—Ä–µ–¥ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–µ–π
for i, frame in enumerate(frames):
    if "close_orig" not in frame.columns and "close" in frame.columns:
        frames[i] = frame.copy()  # –í–∞–∂–Ω–æ: –∫–æ–ø–∏—è –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –º—É—Ç–∞—Ü–∏–∏
        frames[i]["close"] = frame["close"].shift(1)

# –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä–æ–≤–∞—Ç—å
big = pd.concat(frames, axis=0, ignore_index=True)
```

### Impact Score: 10/10
**–ü–æ—á–µ–º—É –∫—Ä–∏—Ç–∏—á–Ω–æ:**
- –í–ª–∏—è–µ—Ç –Ω–∞ –í–°–ï –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–∏ –º—É–ª—å—Ç–∏—Å–∏–º–≤–æ–ª—å–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏
- –ö–æ—Ä—Ä—É–º–ø–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
- –°–æ–∑–¥–∞–µ—Ç –ª–æ–∂–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –Ω–µ—Å–≤—è–∑–∞–Ω–Ω—ã–º–∏ –∞–∫—Ç–∏–≤–∞–º–∏
- –ú–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –Ω–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞—Ö, –Ω–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

---

## CRITICAL #3: Inverted Quantile Loss Asymmetry

**–§–∞–π–ª:** [distributional_ppo.py:2684-2687](distributional_ppo.py#L2684-L2687)
**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** Distributional Value Head
**Severity:** üî¥ CRITICAL (Backward Compatibility Issue)

### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
–ö–≤–∞–Ω—Ç–∏–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –≤ distributional value head –∏—Å–ø–æ–ª—å–∑—É–µ—Ç **–∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ–æ—Ä–º—É–ª—É** –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é. –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ –¥–ª—è –∫–≤–∞–Ω—Ç–∏–ª—å–Ω–æ–≥–æ loss —ç—Ç–æ `delta = target - prediction`, –Ω–æ –∫–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `delta = prediction - target`, —á—Ç–æ –ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç –∞—Å–∏–º–º–µ—Ç—Ä–∏—é –Ω–µ–¥–æ–æ—Ü–µ–Ω–∫–∏/–ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∏.

### –¢–µ–∫—É—â–∏–π –∫–æ–¥:
```python
# DEFAULT MODE (INCORRECT):
delta = predicted_quantiles - targets  # Q - T ‚Üê –ü–ï–†–ï–í–ï–†–ù–£–¢–û!

# CORRECT MODE (via flag):
if self._use_fixed_quantile_loss_asymmetry:
    delta = targets - predicted_quantiles  # T - Q ‚úì
```

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:
**–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ –∫–≤–∞–Ω—Ç–∏–ª—å–Ω–æ–≥–æ loss** (Dabney et al. 2018, QR-DQN):
```
L_œÑ(Œ∏) = E[(œÑ - ùüô{T < Q_Œ∏(œÑ)}) ¬∑ (T - Q_Œ∏(œÑ))]

–≥–¥–µ:
- T = target
- Q_Œ∏(œÑ) = predicted quantile
- ùüô{T < Q_Œ∏(œÑ)} = indicator function
- œÑ = quantile level (e.g., 0.05, 0.5, 0.95)
```

**–ê—Å–∏–º–º–µ—Ç—Ä–∏—è:**
- –ö–æ–≥–¥–∞ `T > Q` (–Ω–µ–¥–æ–æ—Ü–µ–Ω–∫–∞): penalty = `œÑ ¬∑ (T - Q)`
- –ö–æ–≥–¥–∞ `T < Q` (–ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∞): penalty = `(1-œÑ) ¬∑ (Q - T)`

**–° –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ñ–æ—Ä–º—É–ª–æ–π:**
- –ö–æ–≥–¥–∞ `Q > T` (–ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∞): penalty = `œÑ ¬∑ (Q - T)` ‚Üê –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å `(1-œÑ)`!
- –ö–æ–≥–¥–∞ `Q < T` (–Ω–µ–¥–æ–æ—Ü–µ–Ω–∫–∞): penalty = `(1-œÑ) ¬∑ (T - Q)` ‚Üê –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å `œÑ`!

### –í–ª–∏—è–Ω–∏–µ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ:
- **–î–ª—è CVaR (œÑ=0.05, worst 5% tail):**
  - –ü—Ä–∞–≤–∏–ª—å–Ω–æ: —Å–∏–ª—å–Ω–æ –Ω–∞–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–¥–æ–æ—Ü–µ–Ω–∫—É —Ä–∏—Å–∫–æ–≤ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç 0.05)
  - –ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: —Å–ª–∞–±–æ –Ω–∞–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–¥–æ–æ—Ü–µ–Ω–∫—É —Ä–∏—Å–∫–æ–≤ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç 0.95)
  - **–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ú–æ–¥–µ–ª—å –Ω–µ–¥–æ–æ—Ü–µ–Ω–∏–≤–∞–µ—Ç tail —Ä–∏—Å–∫–∏!

- **–î–ª—è –º–µ–¥–∏–∞–Ω—ã (œÑ=0.5):**
  - –°–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ, —ç—Ñ—Ñ–µ–∫—Ç –º–∏–Ω–∏–º–∞–ª–µ–Ω

- **–î–ª—è –≤–µ—Ä—Ö–Ω–∏—Ö –∫–≤–∞–Ω—Ç–∏–ª–µ–π (œÑ=0.95):**
  - –ü—Ä–∞–≤–∏–ª—å–Ω–æ: —Å–ª–∞–±–æ –Ω–∞–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–¥–æ–æ—Ü–µ–Ω–∫—É –ø—Ä–∏–±—ã–ª–∏
  - –ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: —Å–∏–ª—å–Ω–æ –Ω–∞–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–µ–¥–æ–æ—Ü–µ–Ω–∫—É –ø—Ä–∏–±—ã–ª–∏
  - **–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ—Ü–µ–Ω–∏–≤–∞–µ—Ç upside!

### –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ:
```python
# –î–ª—è –í–°–ï–• –Ω–æ–≤—ã—Ö —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫:
model = DistributionalPPO(
    ...,
    _use_fixed_quantile_loss_asymmetry=True,  # –í–∫–ª—é—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ñ–æ—Ä–º—É–ª—É
)
```

### Backward Compatibility:
```python
# –î–ª—è –°–¢–ê–†–´–• –º–æ–¥–µ–ª–µ–π (trained with inverted formula):
model = DistributionalPPO(
    ...,
    _use_fixed_quantile_loss_asymmetry=False,  # –û—Å—Ç–∞–≤–∏—Ç—å —Å—Ç–∞—Ä—É—é —Ñ–æ—Ä–º—É–ª—É
)
```

### Impact Score: 8/10
**–ü–æ—á–µ–º—É –∫—Ä–∏—Ç–∏—á–Ω–æ (–Ω–æ –Ω–µ 10/10):**
- –í–ª–∏—è–µ—Ç –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ value function, –Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ
- –û—Å–æ–±–µ–Ω–Ω–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è CVaR (tail risk –Ω–µ–¥–æ–æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è)
- –û–±—Ä–∞—Ç–∏–º–æ: –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ñ–æ—Ä–º—É–ª–æ–π
- Backward compatibility preserved —á–µ—Ä–µ–∑ —Ñ–ª–∞–≥

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**
- –î–ª—è –Ω–æ–≤—ã—Ö —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫: –í–°–ï–ì–î–ê `_use_fixed_quantile_loss_asymmetry=True`
- –î–ª—è —Å—Ç–∞—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π: –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ CVaR estimates, –≤–æ–∑–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å
- –í v3.0: —Å–¥–µ–ª–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ñ–æ—Ä–º—É–ª—É –¥–µ—Ñ–æ–ª—Ç–Ω–æ–π, —É–±—Ä–∞—Ç—å —Ñ–ª–∞–≥

---

# üü† HIGH PRIORITY ISSUES (5)

## HIGH #1: Population vs Sample Standard Deviation

**–§–∞–π–ª:** [features_pipeline.py:170](features_pipeline.py#L170)
**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** Feature Normalization
**Severity:** üü† HIGH

### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
–ü—Ä–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **population standard deviation** (`ddof=0`) –≤–º–µ—Å—Ç–æ **sample standard deviation** (`ddof=1`). –≠—Ç–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –¥–ª—è ML preprocessing.

### –¢–µ–∫—É—â–∏–π –∫–æ–¥:
```python
m = float(np.nanmean(v))
s = float(np.nanstd(v, ddof=0))  # ‚Üê Population std (–¥–µ–ª–∏—Ç –Ω–∞ N)
```

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–Ω–∏—Ü–∞:
```
Population std: œÉ = ‚àö(Œ£(xi - Œº)¬≤ / N)
Sample std:     s = ‚àö(Œ£(xi - Œº)¬≤ / (N-1))

Bias = œÉ / s = ‚àö((N-1)/N)
```

### –ß–∏—Å–ª–µ–Ω–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ:
| N (—Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏) | Bias | % –æ—à–∏–±–∫–∞ |
|-------------------|------|----------|
| 10 | 0.949 | 5.1% |
| 100 | 0.995 | 0.5% |
| 1000 | 0.9995 | 0.05% |
| 10000 | 0.99995 | 0.005% |

### –ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ:
**–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ç–µ–æ—Ä–∏—è:**
- Training set —ç—Ç–æ **–≤—ã–±–æ—Ä–∫–∞** –∏–∑ –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–π —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π
- Population std –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–≥–¥–∞ —É –≤–∞—Å **–≤—Å—è –ø–æ–ø—É–ª—è—Ü–∏—è**
- Sample std –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–≥–¥–∞ —É –≤–∞—Å **–≤—ã–±–æ—Ä–∫–∞** –∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –Ω–µ—Å–º–µ—â–µ–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É variance

**ML Best Practice:**
- scikit-learn –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `ddof=1` –≤ StandardScaler
- PyTorch BatchNorm –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `unbiased=True` (—ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç `ddof=1`)
- –í—Å–µ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ —Ä–∞–±–æ—Ç—ã –ø–æ preprocessing —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç sample std

### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –≤–ª–∏—è–Ω–∏–µ:
- **–î–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (N > 1000):** –≤–ª–∏—è–Ω–∏–µ < 0.1%, –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–∑–∞–º–µ—Ç–Ω–æ
- **–î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ (N < 100):** –≤–ª–∏—è–Ω–∏–µ > 0.5%, –∑–∞–º–µ—Ç–Ω–æ
- **–î–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏/—Ç–µ—Å—Ç–∞:** –µ—Å–ª–∏ splits –º–∞–ª–µ–Ω—å–∫–∏–µ, bias –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–º

### –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ:
```python
m = float(np.nanmean(v))
s = float(np.nanstd(v, ddof=1))  # Sample std (–Ω–µ—Å–º–µ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
```

### Impact Score: 6/10
**–ü–æ—á–µ–º—É HIGH, –Ω–æ –Ω–µ CRITICAL:**
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ (–Ω–∞—Ä—É—à–∞–µ—Ç best practices)
- –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –≤–ª–∏—è–Ω–∏–µ –º–∞–ª–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
- –õ–µ–≥–∫–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å (–æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞)
- –ù–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –æ–±—É—á–µ–Ω–∏—è

---

## HIGH #2: Taker Buy Ratio Momentum Threshold Too High

**–§–∞–π–ª:** Feature calculation (exact location inferred from audit)
**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** Feature Engineering
**Severity:** üü† HIGH

### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
–†–∞—Å—á–µ—Ç momentum (rate of change) –¥–ª—è `taker_buy_ratio` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç threshold `0.01` –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–Ω–∞—á–∏–º–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è. –≠—Ç–æ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥, –∫–æ—Ç–æ—Ä—ã–π –±–ª–æ–∫–∏—Ä—É–µ—Ç –≤–∞–ª–∏–¥–Ω—ã–µ momentum —Å–∏–≥–Ω–∞–ª—ã –≤–æ–∫—Ä—É–≥ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è (0.5).

### –ö–æ–Ω—Ç–µ–∫—Å—Ç:
`taker_buy_ratio` —ç—Ç–æ –¥–æ–ª—è –ø–æ–∫—É–ø–æ–∫ taker –≤ –æ–±—â–µ–º –æ–±—ä–µ–º–µ:
- `0.5` = –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ä—ã–Ω–æ–∫ (50% buyers, 50% sellers)
- `> 0.5` = –ø–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ
- `< 0.5` = –¥–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–≤—Ü–æ–≤
- –¢–∏–ø–∏—á–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω: `[0.45, 0.55]` –≤ —Å–ø–æ–∫–æ–π–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã

### –ü—Ä–æ–±–ª–µ–º–∞ —Å threshold = 0.01:
```python
# –ü—Å–µ–≤–¥–æ–∫–æ–¥ (—Ç–æ—á–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤ feature_config.py/features/)
delta = taker_buy_ratio[t] - taker_buy_ratio[t-1]

if abs(delta) < 0.01:  # Threshold —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π!
    momentum = 0.0  # –°–∏–≥–Ω–∞–ª –±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è
else:
    momentum = delta / taker_buy_ratio[t-1]
```

**–ü—Ä–∏–º–µ—Ä:**
```
–°–ª—É—á–∞–π 1: –í–æ–∫—Ä—É–≥ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
t-1: taker_buy_ratio = 0.50
t:   taker_buy_ratio = 0.505
delta = 0.005 < 0.01 ‚Üê BLOCKED!
momentum = 0.0

–ù–æ —ç—Ç–æ 1% –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ:
true_momentum = 0.005 / 0.50 = 0.01 = 1%

–°–ª—É—á–∞–π 2: –ü—Ä–∏ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö
t-1: taker_buy_ratio = 0.80
t:   taker_buy_ratio = 0.81
delta = 0.01 >= 0.01 ‚Üê PASSED
momentum = 0.01 / 0.80 = 0.0125 = 1.25%
```

### –í–ª–∏—è–Ω–∏–µ –Ω–∞ feature quality:
- **–í–æ–∫—Ä—É–≥ 0.5 (–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ä—ã–Ω–æ–∫):** –ë–ª–æ–∫–∏—Ä—É—é—Ç—Å—è –∏–∑–º–µ–Ω–µ–Ω–∏—è < 2% (0.01 / 0.5)
- **–ü—Ä–∏ 0.7 (–±—ã—á–∏–π —Ä—ã–Ω–æ–∫):** –ë–ª–æ–∫–∏—Ä—É—é—Ç—Å—è –∏–∑–º–µ–Ω–µ–Ω–∏—è < 1.4% (0.01 / 0.7)
- **–ü—Ä–∏ 0.3 (–º–µ–¥–≤–µ–∂–∏–π —Ä—ã–Ω–æ–∫):** –ë–ª–æ–∫–∏—Ä—É—é—Ç—Å—è –∏–∑–º–µ–Ω–µ–Ω–∏—è < 3.3% (0.01 / 0.3)

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ú–æ–¥–µ–ª—å –Ω–µ –≤–∏–¥–∏—Ç —Ç–æ–Ω–∫–∏–µ momentum —Å–∏–≥–Ω–∞–ª—ã –≤ balanced markets.

### –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ:
**Option 1: Lower absolute threshold**
```python
if abs(delta) < 0.005:  # –í–¥–≤–æ–µ –º–µ–Ω—å—à–µ (0.5% near 0.5)
    momentum = 0.0
else:
    momentum = delta / (taker_buy_ratio[t-1] + 1e-8)
```

**Option 2: Relative threshold (better)**
```python
# Threshold –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
threshold = max(0.005, 0.01 * abs(taker_buy_ratio[t-1]))

if abs(delta) < threshold:
    momentum = 0.0
else:
    momentum = delta / (taker_buy_ratio[t-1] + 1e-8)
```

**Option 3: Remove threshold entirely**
```python
# –ü—É—Å—Ç—å –º–æ–¥–µ–ª—å —Å–∞–º–∞ —Ä–µ—à–∞–µ—Ç —á—Ç–æ –∑–Ω–∞—á–∏–º–æ
momentum = delta / (taker_buy_ratio[t-1] + 1e-8)
```

### Impact Score: 7/10
**–ü–æ—á–µ–º—É HIGH:**
- –í–ª–∏—è–µ—Ç –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –≤–∞–∂–Ω–æ–≥–æ –º–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
- –û—Å–æ–±–µ–Ω–Ω–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è HFT/market-making —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
- –ú–æ–∂–µ—Ç —Å–∫—Ä—ã–≤–∞—Ç—å early warning signals –¥–ª—è —Ä–∞–∑–≤–æ—Ä–æ—Ç–æ–≤ —Ç—Ä–µ–Ω–¥–∞
- –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å

**–ü–æ—á–µ–º—É –Ω–µ CRITICAL:**
- –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫ –∏–∑ 60+ –∑–∞—Ç—Ä–æ–Ω—É—Ç
- –ú–æ–¥–µ–ª—å –∏–º–µ–µ—Ç –¥—Ä—É–≥–∏–µ momentum indicators
- –í–ª–∏—è–µ—Ç –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ –Ω–µ –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å

---

## HIGH #3: Reward Doubling Bug - Missing Regression Test

**–§–∞–π–ª:** [reward.pyx:111](reward.pyx#L111)
**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** Reward Calculation
**Severity:** üü† HIGH

### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
–í –∫–æ–¥–µ –µ—Å—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º –±–∞–≥–µ, –∫–æ—Ç–æ—Ä—ã–π –±—ã–ª –∏—Å–ø—Ä–∞–≤–ª–µ–Ω:
```python
# FIX: –£—Å—Ç—Ä–∞–Ω–µ–Ω –¥–≤–æ–π–Ω–æ–π —É—á–µ—Ç reward! –ë—ã–ª–æ: reward = delta/scale + log_return (—É–¥–≤–æ–µ–Ω–∏–µ!)
# –¢–µ–ø–µ—Ä—å: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏–±–æ log_return, –ª–∏–±–æ delta/scale, –Ω–æ –ù–ï –æ–±–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
```

**–ü—Ä–æ–±–ª–µ–º–∞:** –ù–µ—Ç regression —Ç–µ—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –±—ã –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–ª, —á—Ç–æ —ç—Ç–æ—Ç –±–∞–≥ –Ω–µ –≤–µ—Ä–Ω–µ—Ç—Å—è.

### –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –±–∞–≥:
```python
# –°–¢–ê–†–ê–Ø (–ù–ï–ü–†–ê–í–ò–õ–¨–ù–ê–Ø) —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:
reward = net_worth_delta / reward_scale  # Scaled delta
if use_legacy_log_reward:
    reward += log_return(net_worth, prev_net_worth)  # ‚Üê –î–û–ë–ê–í–õ–Ø–õ –î–í–ê–ñ–î–´!
```

**–≠—Ñ—Ñ–µ–∫—Ç:** Reward –±—ã–ª —É–¥–≤–æ–µ–Ω, —á—Ç–æ —Å–æ–∑–¥–∞–≤–∞–ª–æ:
- –ü–µ—Ä–µ–æ—Ü–µ–Ω–∫—É returns (2x actual)
- Gradient explosion (2x signal)
- –°—É–±–æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é policy (trained on inflated rewards)

### –¢–µ–∫—É—â–∞—è (–ü–†–ê–í–ò–õ–¨–ù–ê–Ø) —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:
```python
# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è:
if use_legacy_log_reward:
    reward = log_return(net_worth, prev_net_worth)  # –¢–æ–ª—å–∫–æ log
else:
    reward = net_worth_delta / reward_scale  # –¢–æ–ª—å–∫–æ delta
# XOR logic - –ª–∏–±–æ –æ–¥–Ω–æ, –ª–∏–±–æ –¥—Ä—É–≥–æ–µ!
```

### –ü–æ—á–µ–º—É –Ω—É–∂–µ–Ω regression test:
1. **–ó–∞—â–∏—Ç–∞ –æ—Ç —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:** –ö—Ç–æ-—Ç–æ –º–æ–∂–µ—Ç —Å–ª—É—á–∞–π–Ω–æ –≤–µ—Ä–Ω—É—Ç—å —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É
2. **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:** –¢–µ—Å—Ç —Å–ª—É–∂–∏—Ç —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è
3. **–î–æ–≤–µ—Ä–∏–µ:** –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —á—Ç–æ –≤—Å–µ –º–æ–¥–µ–ª–∏ –æ–±—É—á–∞—é—Ç—Å—è —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º reward
4. **Best practice:** –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ bug fixes –≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å —Ç–µ—Å—Ç—ã

### –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π —Ç–µ—Å—Ç:
```python
# test_reward_doubling_regression.py
def test_reward_not_doubled():
    """
    Regression test: Ensure reward is computed using EITHER log_return OR
    scaled_delta, but NOT both (prevents doubling bug).
    """
    # Setup
    net_worth = 1100.0
    prev_net_worth = 1000.0
    reward_scale = 1000.0

    # Test legacy mode (should use ONLY log_return)
    reward_legacy = compute_reward_view(
        net_worth=net_worth,
        prev_net_worth=prev_net_worth,
        use_legacy_log_reward=True,
        # ... other params
    )

    expected_log_return = log_return(net_worth, prev_net_worth)
    assert abs(reward_legacy - expected_log_return) < 1e-6, \
        "Legacy mode should use ONLY log_return"

    # Test new mode (should use ONLY scaled_delta)
    reward_new = compute_reward_view(
        net_worth=net_worth,
        prev_net_worth=prev_net_worth,
        use_legacy_log_reward=False,
        # ... other params
    )

    expected_scaled_delta = (net_worth - prev_net_worth) / reward_scale
    assert abs(reward_new - expected_scaled_delta) < 1e-6, \
        "New mode should use ONLY scaled_delta"

    # Critical check: rewards should NOT be equal to sum
    double_reward = expected_log_return + expected_scaled_delta
    assert abs(reward_legacy - double_reward) > 1e-3, \
        "CRITICAL: Reward doubling bug detected!"
    assert abs(reward_new - double_reward) > 1e-3, \
        "CRITICAL: Reward doubling bug detected!"
```

### Impact Score: 8/10
**–ü–æ—á–µ–º—É HIGH:**
- –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –±–∞–≥ –≤ –ø—Ä–æ—à–ª–æ–º (CRITICAL severity –∫–æ–≥–¥–∞ –±—ã–ª –∞–∫—Ç–∏–≤–µ–Ω)
- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ç–µ—Å—Ç–∞ = —Ä–∏—Å–∫ –≤–æ–∑–≤—Ä–∞—Ç–∞ –±–∞–≥–∞
- –í–ª–∏—è–µ—Ç –Ω–∞ –≤—Å–µ –æ–±—É—á–µ–Ω–∏–µ, –µ—Å–ª–∏ –≤–µ—Ä–Ω–µ—Ç—Å—è
- –õ–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å —Ç–µ—Å—Ç (30 –º–∏–Ω—É—Ç —Ä–∞–±–æ—Ç—ã)

**–ü–æ—á–µ–º—É –Ω–µ CRITICAL —Å–µ–π—á–∞—Å:**
- –ë–∞–≥ –£–ñ–ï –∏—Å–ø—Ä–∞–≤–ª–µ–Ω
- –¢–æ–ª—å–∫–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∑–∞—â–∏—Ç–∞ –æ—Ç —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
- –ú–æ–∂–Ω–æ –≤—ã—è–≤–∏—Ç—å code review'–æ–º (–Ω–æ —Ç–µ—Å—Ç –Ω–∞–¥–µ–∂–Ω–µ–µ)

---

## HIGH #4: Potential Shaping Bug - Missing Regression Test

**–§–∞–π–ª:** [reward.pyx:124-137](reward.pyx#L124-L137)
**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** Reward Shaping
**Severity:** üü† HIGH

### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
–ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É, –µ—Å—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º –±–∞–≥–µ:
```python
# FIX CRITICAL BUG: Apply potential shaping regardless of reward mode
# Previously, potential shaping was only applied when use_legacy_log_reward=True,
# causing it to be ignored in the new reward mode even when enabled
```

**–ù–µ—Ç regression —Ç–µ—Å—Ç–∞ –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∏–∫—Å–∞.**

### –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –±–∞–≥:
```python
# –°–¢–ê–†–ê–Ø (–ù–ï–ü–†–ê–í–ò–õ–¨–ù–ê–Ø) —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:
if use_legacy_log_reward:
    reward = log_return(...)
    if use_potential_shaping:
        reward += potential_shaping(...)  # –ü—Ä–∏–º–µ–Ω—è–ª–æ—Å—å —Ç–æ–ª—å–∫–æ –∑–¥–µ—Å—å
else:
    reward = net_worth_delta / reward_scale
    # Potential shaping –ù–ï –ø—Ä–∏–º–µ–Ω—è–ª–æ—Å—å! ‚Üê –ë–ê–ì
```

**–≠—Ñ—Ñ–µ–∫—Ç:**
- –ö–æ–Ω—Ñ–∏–≥ —Å `use_potential_shaping=True` –∏ `use_legacy_log_reward=False` **–º–æ–ª—á–∞ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª** shaping
- –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–ª–∞—Å—å –±–µ–∑ risk-averse penalties, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã
- –í—ã—Å–æ–∫–∞—è variance –≤ training (shaping –¥–æ–ª–∂–µ–Ω –±—ã–ª —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å)
- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∑–Ω–∞–ª —á—Ç–æ shaping –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç (no warning)

### –¢–µ–∫—É—â–∞—è (–ü–†–ê–í–ò–õ–¨–ù–ê–Ø) —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:
```python
# Compute base reward (either mode)
if use_legacy_log_reward:
    reward = log_return(net_worth, prev_net_worth)
else:
    reward = net_worth_delta / reward_scale

# Apply potential shaping INDEPENDENTLY
if use_potential_shaping:
    phi_t = potential_phi(...)
    reward += potential_shaping(gamma, last_potential, phi_t)
    # ‚Üë –¢–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –û–ë–û–ò–• —Ä–µ–∂–∏–º–∞—Ö!
```

### –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π —Ç–µ—Å—Ç:
```python
# test_potential_shaping_regression.py
def test_potential_shaping_both_modes():
    """
    Regression test: Ensure potential shaping is applied in BOTH
    use_legacy_log_reward=True and False modes.
    """
    # Setup
    net_worth = 1100.0
    prev_net_worth = 1000.0
    units = 10.0
    atr = 5.0
    peak_value = 1200.0

    # Compute expected phi (risk/drawdown penalties)
    phi_t = potential_phi(
        net_worth, peak_value, units, atr,
        risk_aversion_variance=0.1,
        risk_aversion_drawdown=0.2,
        potential_shaping_coef=0.5,
    )

    # Test legacy mode WITH shaping
    reward_legacy_shaped = compute_reward_view(
        net_worth=net_worth,
        prev_net_worth=prev_net_worth,
        use_legacy_log_reward=True,
        use_potential_shaping=True,
        # ... phi params
    )

    # Test legacy mode WITHOUT shaping
    reward_legacy_no_shape = compute_reward_view(
        net_worth=net_worth,
        prev_net_worth=prev_net_worth,
        use_legacy_log_reward=True,
        use_potential_shaping=False,
        # ... phi params
    )

    # Shaping should make a difference in legacy mode
    assert abs(reward_legacy_shaped - reward_legacy_no_shape) > 1e-6, \
        "Potential shaping should affect legacy mode"

    # Test NEW mode WITH shaping
    reward_new_shaped = compute_reward_view(
        net_worth=net_worth,
        prev_net_worth=prev_net_worth,
        use_legacy_log_reward=False,
        use_potential_shaping=True,
        # ... phi params
    )

    # Test NEW mode WITHOUT shaping
    reward_new_no_shape = compute_reward_view(
        net_worth=net_worth,
        prev_net_worth=prev_net_worth,
        use_legacy_log_reward=False,
        use_potential_shaping=False,
        # ... phi params
    )

    # CRITICAL: Shaping should ALSO make a difference in new mode!
    assert abs(reward_new_shaped - reward_new_no_shape) > 1e-6, \
        "CRITICAL BUG: Potential shaping not applied in new reward mode!"
```

### Impact Score: 8/10
**–ü–æ—á–µ–º—É HIGH:**
- –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –±–∞–≥ –≤ –ø—Ä–æ—à–ª–æ–º (–º–æ–ª—á–∞–ª–∏–≤—ã–π –æ—Ç–∫–∞–∑ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞)
- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ç–µ—Å—Ç–∞ = —Ä–∏—Å–∫ –≤–æ–∑–≤—Ä–∞—Ç–∞ –±–∞–≥–∞
- –í–ª–∏—è–µ—Ç –Ω–∞ training stability –µ—Å–ª–∏ –≤–µ—Ä–Ω–µ—Ç—Å—è
- Potential shaping —ç—Ç–æ –≤–∞–∂–Ω–∞—è –æ–ø—Ü–∏—è –¥–ª—è risk-averse training

---

## HIGH #5: Missing Test for Cross-Symbol Normalization

**–§–∞–π–ª:** –ù–µ—Ç (—Ç–µ—Å—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)
**–°–≤—è–∑–∞–Ω —Å:** CRITICAL #2
**Severity:** üü† HIGH

### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
CRITICAL #2 (Cross-Symbol Contamination) –Ω–µ –∏–º–µ–µ—Ç —Ç–µ—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –±—ã –ø—Ä–æ–≤–µ—Ä—è–ª –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —É—Ç–µ—á–∫–∏ –º–µ–∂–¥—É —Å–∏–º–≤–æ–ª–∞–º–∏ –ø—Ä–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.

### –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π —Ç–µ—Å—Ç:
```python
# test_feature_pipeline_no_cross_symbol_leak.py
def test_no_cross_symbol_contamination():
    """
    Ensure that shift(1) on 'close' doesn't leak last value of Symbol1
    into first value of Symbol2 when normalizing multiple symbols.
    """
    # Create synthetic data for two symbols
    btc_data = pd.DataFrame({
        'symbol': ['BTCUSDT'] * 100,
        'ts': range(100),
        'close': np.linspace(100, 200, 100),  # BTC: 100 ‚Üí 200
        'volume': np.random.randn(100),
    })

    eth_data = pd.DataFrame({
        'symbol': ['ETHUSDT'] * 100,
        'ts': range(100, 200),
        'close': np.linspace(1000, 2000, 100),  # ETH: 1000 ‚Üí 2000
        'volume': np.random.randn(100),
    })

    # Create frames dict
    frames = [btc_data, eth_data]

    # Apply feature pipeline
    pipeline = FeaturePipeline()
    pipeline.fit(frames, ...)

    # Extract normalized data
    normalized = pipeline.transform_df(frames)

    # CRITICAL CHECK: First row of ETH should NOT contain BTC's last value
    btc_section = normalized[normalized['symbol'] == 'BTCUSDT']
    eth_section = normalized[normalized['symbol'] == 'ETHUSDT']

    # Get shifted close values
    btc_close_shifted = btc_section['close'].iloc[-1]  # Last BTC value
    eth_close_shifted = eth_section['close'].iloc[0]   # First ETH value

    # These should be VERY different (no leak)
    # BTC last: ~200, ETH first: NaN (after shift)
    assert pd.isna(eth_close_shifted) or abs(eth_close_shifted - btc_close_shifted) > 500, \
        "CRITICAL: Cross-symbol contamination detected! BTC value leaked into ETH."

    # Alternative check: Verify shift was applied per-symbol
    # BTC first shifted value should be NaN
    assert pd.isna(btc_section['close'].iloc[0]), \
        "Shift not applied correctly to BTC"

    # ETH first shifted value should be NaN (not BTC's last value!)
    assert pd.isna(eth_section['close'].iloc[0]), \
        "CRITICAL: ETH first value should be NaN, not BTC's last value!"
```

### Impact Score: 7/10
**–ü–æ—á–µ–º—É HIGH:**
- –ó–∞—â–∏—â–∞–µ—Ç CRITICAL bug fix
- –ë–µ–∑ —Ç–µ—Å—Ç–∞ –±–∞–≥ –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å—Å—è –Ω–µ–∑–∞–º–µ—Ç–Ω–æ
- Multi-symbol training —ç—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π use case
- –¢–µ—Å—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—Å–∞—Ç—å

---

# üü° MEDIUM PRIORITY ISSUES (14)

## MEDIUM #1: Return Fallback to 0.0 Instead of NaN

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** Feature Calculation
**Severity:** üü° MEDIUM

### –û–ø–∏—Å–∞–Ω–∏–µ:
–ü—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ returns, –µ—Å–ª–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–µ—Ä–≤—ã–π –±–∞—Ä), fallback –∑–Ω–∞—á–µ–Ω–∏–µ —ç—Ç–æ `0.0` –≤–º–µ—Å—Ç–æ `NaN`.

### –ü—Ä–æ–±–ª–µ–º–∞:
- `0.0` –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ "–Ω–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã"
- `NaN` –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–∏–≥–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
- –ú–æ–¥–µ–ª—å –Ω–µ –º–æ–∂–µ—Ç —Ä–∞–∑–ª–∏—á–∏—Ç—å —ç—Ç–∏ –¥–≤–∞ —Å–ª—É—á–∞—è
- Validity flags —Ç–µ—Ä—è—é—Ç —Å–º—ã—Å–ª

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:
```python
if prev_price <= 0:
    return np.nan  # –ù–µ 0.0!
else:
    return (price - prev_price) / prev_price
```

**Impact:** 4/10 - –í–ª–∏—è–µ—Ç –Ω–∞ –ø–µ—Ä–≤—ã–µ bars –∫–∞–∂–¥–æ–≥–æ episode

---

## MEDIUM #2: Parkinson Volatility Uses valid_bars Instead of n

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** Volatility Estimators
**Severity:** üü° MEDIUM

### –û–ø–∏—Å–∞–Ω–∏–µ:
Parkinson volatility formula –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `valid_bars` (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö) –≤–º–µ—Å—Ç–æ `n` (—Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞) –≤ –∑–Ω–∞–º–µ–Ω–∞—Ç–µ–ª–µ.

### –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∞—è —Ñ–æ—Ä–º—É–ª–∞:
```
œÉ_Parkinson = ‚àö(1/(4n¬∑ln2) ¬∑ Œ£(ln(H/L))¬≤)
```

### –¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:
```
œÉ_Parkinson = ‚àö(1/(4¬∑valid_bars¬∑ln2) ¬∑ Œ£(ln(H/L))¬≤)
```

### –í–æ–ø—Ä–æ—Å:
–≠—Ç–æ –æ—Å–æ–∑–Ω–∞–Ω–Ω—ã–π –≤—ã–±–æ—Ä (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å effective sample size) –∏–ª–∏ –æ—à–∏–±–∫–∞?

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:
- **–ï—Å–ª–∏ intentional:** –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π explaining why
- **–ï—Å–ª–∏ error:** –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ `n`

**Impact:** 5/10 - –í–ª–∏—è–µ—Ç –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å volatility estimates

---

## MEDIUM #3: No Outlier Detection for Returns

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** Feature Calculation
**Severity:** üü° MEDIUM

### –û–ø–∏—Å–∞–Ω–∏–µ:
–ù–µ—Ç –∑–∞—â–∏—Ç—ã –æ—Ç —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö returns (flash crashes, liquidations, fat-finger trades).

### –ü—Ä–æ–±–ª–µ–º–∞:
–û–¥–∏–Ω —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π return –º–æ–∂–µ—Ç:
- –î–æ–º–∏–Ω–∏—Ä–æ–≤–∞—Ç—å –≤ mean/std —Ä–∞—Å—á–µ—Ç–∞—Ö
- –°–æ–∑–¥–∞—Ç—å —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ normalized values
- –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ anomalies –≤–º–µ—Å—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ behavior

### –ü—Ä–∏–º–µ—Ä:
```
Normal returns: [-0.1%, +0.2%, -0.05%, +0.15%, ...]
Flash crash: -50%  ‚Üê Outlier

Mean –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: -2.5%  ‚Üê –°–¥–≤–∏–Ω—É—Ç outlier'–æ–º
Std –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: 15%     ‚Üê –†–∞–∑–¥—É—Ç outlier'–æ–º
```

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:
```python
# Option 1: Winsorization
returns = np.clip(returns,
                  np.percentile(returns, 1),   # 1st percentile
                  np.percentile(returns, 99))  # 99th percentile

# Option 2: Z-score filtering
z_scores = np.abs((returns - returns.mean()) / returns.std())
returns_clean = returns[z_scores < 3]  # Remove > 3 sigma

# Option 3: MAD (Median Absolute Deviation)
median = np.median(returns)
mad = np.median(np.abs(returns - median))
threshold = median + 3 * 1.4826 * mad  # 1.4826 converts MAD to std
returns_clean = returns[returns < threshold]
```

**Impact:** 6/10 - –í–∞–∂–Ω–æ –¥–ª—è robustness, –Ω–æ —Ä–µ–¥–∫–æ –ø—Ä–æ—è–≤–ª—è–µ—Ç—Å—è

---

## MEDIUM #4: Zero Std Fallback to 1.0 Doesn't Normalize

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç:** Feature Normalization
**Severity:** üü° MEDIUM

### –û–ø–∏—Å–∞–Ω–∏–µ:
–ö–æ–≥–¥–∞ feature –∏–º–µ–µ—Ç –Ω—É–ª–µ–≤—É—é variance, fallback —ç—Ç–æ `std = 1.0`, —á—Ç–æ –Ω–µ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç constant features.

### –¢–µ–∫—É—â–µ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ:
```python
if std == 0.0:
    std = 1.0

normalized = (value - mean) / std
# –ï—Å–ª–∏ value –≤—Å–µ–≥–¥–∞ = C (constant):
# mean = C
# normalized = (C - C) / 1.0 = 0.0  ‚Üê –ü—Ä–∞–≤–∏–ª—å–Ω–æ!
```

**–ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ —ç—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!** Constant feature ‚Üí normalized to 0.

### –ù–æ –µ—Å—Ç—å edge case:
–ï—Å–ª–∏ mean –ù–ï —Ä–∞–≤–µ–Ω –∫–æ–Ω—Å—Ç–∞–Ω—Ç–µ (–∏–∑-–∑–∞ NaN –∏–ª–∏ –¥—Ä—É–≥–∏—Ö issues):
```python
values = [100, 100, 100, NaN, 100]  # –ü–æ—Å–ª–µ nanmean
mean = 100
std = 0.0 ‚Üí fallback to 1.0
normalized = (100 - 100) / 1.0 = 0.0  # OK

# –ù–æ –µ—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∞ –≤ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ mean:
mean = 99  # –ü–æ—á–µ–º—É-—Ç–æ –Ω–µ 100
normalized = (100 - 99) / 1.0 = 1.0  # –ù–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ!
```

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:
```python
if std < 1e-8:  # Effectively zero
    # Option 1: Explicit zero
    normalized = np.zeros_like(values)

    # Option 2: Center only
    normalized = values - mean  # Don't divide by 1.0

    # Option 3: Current (keep as is, but document)
    normalized = (values - mean) / 1.0
```

**Impact:** 3/10 - –û—á–µ–Ω—å —Ä–µ–¥–∫–∏–π edge case

---

## MEDIUM #5: Lookahead Bias in Close Price Shifting

**–§–∞–π–ª:** [features_pipeline.py:163-164, 213-214](features_pipeline.py)
**Severity:** üü° MEDIUM

### –û–ø–∏—Å–∞–Ω–∏–µ:
`shift(1)` –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫ `close` –≤ –¥–≤—É—Ö –º–µ—Å—Ç–∞—Ö: –≤ `fit()` –∏ –≤ `transform_df()`. –ï—Å—Ç—å —Ä–∏—Å–∫ double-shifting.

### –†–∏—Å–∫:
```python
# –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —É–∂–µ shifted –Ω–∞ –≤—Ö–æ–¥–µ:
data_shifted_once = load_data()  # close —É–∂–µ shifted

# –ó–∞—Ç–µ–º –≤ fit():
big["close"] = big["close"].shift(1)  # Shift #2

# –ó–∞—Ç–µ–º –≤ transform_df():
out["close"] = out["close"].shift(1)  # Shift #3!

# –†–µ–∑—É–ª—å—Ç–∞—Ç: triple shift, –ø–æ—Ç–µ—Ä—è 3 data points
```

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:
- –î–æ–±–∞–≤–∏—Ç—å —Ñ–ª–∞–≥ `_close_shifted` –≤ pipeline
- Shift —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –≤ –∂–∏–∑–Ω–µ–Ω–Ω–æ–º —Ü–∏–∫–ª–µ
- –ò–õ–ò: shift –≤ data loading, –Ω–µ –≤ pipeline

**Impact:** 5/10 - –ó–∞–≤–∏—Å–∏—Ç –æ—Ç data flow, –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–≤–∏–¥–∏–º—ã–º

---

## MEDIUM #6: Unrealistic Data Degradation Patterns

**–§–∞–π–ª:** [data_validation.py](data_validation.py), [impl_offline_data.py](impl_offline_data.py)
**Severity:** üü° MEDIUM

### –û–ø–∏—Å–∞–Ω–∏–µ:
Data degradation simulation –∏—Å–ø–æ–ª—å–∑—É–µ—Ç IID (independent) probabilities –¥–ª—è stale/drop/dropout. –†–µ–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏ –∏–º–µ—é—Ç **correlated failures**.

### –¢–µ–∫—É—â–∞—è —Å–∏–º—É–ª—è—Ü–∏—è:
```python
# –ö–∞–∂–¥—ã–π –±–∞—Ä –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ:
if random() < stale_prob:
    return stale_bar

if random() < drop_prob:
    drop bar
```

### –ü—Ä–æ–±–ª–µ–º–∞:
- –†–µ–∞–ª—å–Ω—ã–µ —Å–µ—Ç–µ–≤—ã–µ —Å–±–æ–∏ **–∫–ª–∞—Å—Ç–µ—Ä–∏–∑—É—é—Ç—Å—è** (burst failures)
- –ü–æ—Å–ª–µ dropout —á–∞—Å—Ç–æ –∏–¥–µ—Ç burst recovery (queue flush)
- Fixed seed –¥–µ–ª–∞–µ—Ç degradation **deterministic** –º–µ–∂–¥—É runs

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è - Markov Chain Model:
```python
class NetworkStateModel:
    def __init__(self):
        self.state = 'NORMAL'  # NORMAL, DEGRADED, FAILED
        self.transition_probs = {
            'NORMAL': {'NORMAL': 0.98, 'DEGRADED': 0.015, 'FAILED': 0.005},
            'DEGRADED': {'NORMAL': 0.3, 'DEGRADED': 0.6, 'FAILED': 0.1},
            'FAILED': {'NORMAL': 0.1, 'DEGRADED': 0.2, 'FAILED': 0.7},
        }

    def step(self):
        self.state = random.choices(
            list(self.transition_probs[self.state].keys()),
            weights=list(self.transition_probs[self.state].values())
        )[0]

        if self.state == 'DEGRADED':
            return 'stale' if random() < 0.5 else 'delayed'
        elif self.state == 'FAILED':
            return 'drop'
        else:
            return 'normal'
```

**Impact:** 5/10 - –ú–æ–∂–µ—Ç –≤—ã–∑–≤–∞—Ç—å overfitting –∫ specific degradation pattern

---

## MEDIUM #7: Double Turnover Penalty

**–§–∞–π–ª:** [reward.pyx:153-154](reward.pyx#L153-L154)
**Severity:** üü° MEDIUM

### –û–ø–∏—Å–∞–Ω–∏–µ:
–°–∏—Å—Ç–µ–º–∞ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –î–í–ê penalty –Ω–∞ trading:
1. Transaction costs: `taker_fee + spread + impact` (~0.12%)
2. Turnover penalty: `turnover_penalty_coef * notional` (~0.05%)

**Total:** ~0.17% per trade

### –í–æ–ø—Ä–æ—Å:
–≠—Ç–æ intentional "double penalty" —á—Ç–æ–±—ã discourage overtrading, –∏–ª–∏ oversight?

### –ê—Ä–≥—É–º–µ–Ω—Ç—ã "–∑–∞" double penalty:
- Transaction costs = —Ä–µ–∞–ª—å–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã
- Turnover penalty = behavioral —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
- –í–º–µ—Å—Ç–µ = —Å–∏–ª—å–Ω–µ–µ discourage high-frequency trading

### –ê—Ä–≥—É–º–µ–Ω—Ç—ã "–ø—Ä–æ—Ç–∏–≤":
- Redundant - –æ–±–∞ –Ω–∞–∫–∞–∑—ã–≤–∞—é—Ç –∑–∞ –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ
- –ú–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–º
- –õ—É—á—à–µ –∏–º–µ—Ç—å –æ–¥–∏–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ç–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–π penalty

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:
**–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å** —ç—Ç–æ—Ç design choice —è–≤–Ω–æ:
```python
# Intentional double penalty:
# 1. Transaction costs = —Ä–µ–∞–ª—å–Ω—ã–µ market costs
# 2. Turnover penalty = –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ç–∏–≤ overtrading
# Total ~0.17% creates conservative trading behavior
```

**–ò–õ–ò** —É–±—Ä–∞—Ç—å –æ–¥–∏–Ω, —É–≤–µ–ª–∏—á–∏—Ç—å –¥—Ä—É–≥–æ–π.

**Impact:** 4/10 - –í–ª–∏—è–µ—Ç –Ω–∞ trading frequency, –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å intentional

---

## MEDIUM #8-14: (–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ)

**#8: Event Reward Logic** - –í—Å–µ non-TP closes –ø–æ–ª—É—á–∞—é—Ç loss penalty (–¥–∞–∂–µ timeout)
**Impact:** 4/10

**#9: Hard-coded Reward Clip** - `reward_cap` hardcoded –≤–º–µ—Å—Ç–æ —á—Ç–µ–Ω–∏—è –∏–∑ config
**Impact:** 3/10

**#10: BB Position Asymmetric Clipping** - `[-1.0, 2.0]` –≤–º–µ—Å—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ `[0, 1]`
**Impact:** 3/10

**#11: BB Squeeze Normalization** - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –¥—Ä—É–≥–æ–π scale —á–µ–º –¥—Ä—É–≥–∏–µ indicators
**Impact:** 3/10

**#12: Bankruptcy State Ambiguity** - `total_worth=0` –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç "100% cash" –≤–º–µ—Å—Ç–æ bankruptcy
**Impact:** 2/10

**#13: Checkpoint Integrity Validation Missing** - –ù–µ—Ç checksum –¥–ª—è saved models
**Impact:** 6/10

**#14: Entropy NaN/Inf Validation Missing** - Entropy loss –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç invalid values
**Impact:** 5/10

---

# üü¢ LOW PRIORITY ISSUES (14)

*(–ö—Ä–∞—Ç–∫–æ–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ - –¥–µ—Ç–∞–ª–∏ –≤ comprehensive report)*

**LOW #1:** Bias correction floor –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç (–º–æ–∂–µ—Ç division by very small number at step=1)
**LOW #2:** Action space validation –≤ PopArt loader
**LOW #3:** Observation bounds validation –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
**LOW #4:** Gradient explosion early stopping –Ω–µ—Ç
**LOW #5:** Batch size validation (min 2 samples)
**LOW #6:** Distribution sanity checks –¥–ª—è probabilities
**LOW #7:** Periodic checkpoint integrity tests
**LOW #8:** Configurable NaN/Inf halt policy
**LOW #9:** Timestamp jitter simulation –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
**LOW #10:** Partial update simulation (price OR volume updated)
**LOW #11:** Burst failure simulation
**LOW #12:** Recovery lag –ø–æ—Å–ª–µ dropout
**LOW #13:** Advantage epsilon —É–≤–µ–ª–∏—á–∏—Ç—å —Å 1e-8 –¥–æ 1e-6
**LOW #14:** –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è –≤—Å–µ—Ö design choices

**Impact Range:** 1-4/10 –¥–ª—è –∫–∞–∂–¥–æ–π

---

# SUMMARY TABLE

| Category | Count | Total Impact | Avg Impact |
|----------|-------|--------------|------------|
| üî¥ CRITICAL | 3 | 27/30 | 9.0/10 |
| üü† HIGH | 5 | 36/50 | 7.2/10 |
| üü° MEDIUM | 14 | 62/140 | 4.4/10 |
| üü¢ LOW | 14 | 35/140 | 2.5/10 |
| **TOTAL** | **36** | **160/360** | **4.4/10** |

---

# PRIORITIZATION MATRIX

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ IMPACT vs EFFORT                                ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ HIGH IMPACT ‚îÇ  CRITICAL #1,#2,#3 (MUST FIX!)   ‚îÇ
‚îÇ             ‚îÇ  HIGH #1,#2,#3,#4,#5             ‚îÇ
‚îÇ             ‚îÇ                                   ‚îÇ
‚îÇ MEDIUM      ‚îÇ  MEDIUM #3,#6,#13,#14            ‚îÇ
‚îÇ IMPACT      ‚îÇ                                   ‚îÇ
‚îÇ             ‚îÇ                                   ‚îÇ
‚îÇ LOW IMPACT  ‚îÇ  MEDIUM #1,#2,#4,#5,#7-#12       ‚îÇ
‚îÇ             ‚îÇ  LOW #1-#14                      ‚îÇ
‚îÇ             ‚îÇ                                   ‚îÇ
‚îÇ             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ               LOW     MEDIUM      HIGH          ‚îÇ
‚îÇ                    EFFORT                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

QUICK WINS (High Impact, Low Effort):
- CRITICAL #1, #2, #3
- HIGH #1 (one line fix)
- HIGH #3, #4, #5 (add tests)

MUST DO (High Impact, Medium Effort):
- HIGH #2 (redesign threshold logic)
- MEDIUM #13 (add validation)

CONSIDER (Medium Impact, Low Effort):
- MEDIUM #1, #4, #9
```

---

**–ò—Ç–æ–≥–æ:** 36 –ø—Ä–æ–±–ª–µ–º –Ω–∞–π–¥–µ–Ω–æ, —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–æ –ø–æ severity –∏ impact. –ù–∞—á–Ω–∏—Ç–µ —Å 3 CRITICAL, –∑–∞—Ç–µ–º 5 HIGH.
