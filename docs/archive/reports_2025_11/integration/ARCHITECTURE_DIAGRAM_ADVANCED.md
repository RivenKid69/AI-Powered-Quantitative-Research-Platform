# Advanced Features Architecture - TradingBot2

**Last Updated**: 2025-11-21
**Version**: 2.1

> Detailed architecture diagrams for advanced features: UPGD, VGS, Twin Critics, PBT, and Critical Fixes

---

## ğŸ†• UPGD Optimizer Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AdaptiveUPGD Optimizer                      â”‚
â”‚                  (Continual Learning)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚   Input: Gradients g_t                                        â”‚
â”‚      â”‚                                                         â”‚
â”‚      â–¼                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 1. Compute Utility      â”‚                                â”‚
â”‚   â”‚    u_t = -g_t Â· p       â”‚  (negative dot product)        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 2. EMA Utility          â”‚                                â”‚
â”‚   â”‚    U_t = Î²Â·U_{t-1}      â”‚                                â”‚
â”‚   â”‚         + (1-Î²)Â·u_t     â”‚  (Î²=0.999 default)             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 3. Gaussian Noise       â”‚                                â”‚
â”‚   â”‚    Îµ ~ N(0, ÏƒÂ²I)        â”‚  (Ïƒ=0.001 with VGS)            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 4. Perturbed Gradient   â”‚                                â”‚
â”‚   â”‚    gÌƒ_t = g_t + Îµ       â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 5. Utility Protection   â”‚                                â”‚
â”‚   â”‚    IF U_t < 0:          â”‚                                â”‚
â”‚   â”‚      gÌƒ_t = -gÌƒ_t       â”‚  (flip direction)              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 6. Adaptive Moments     â”‚  (AdaptiveUPGD only)           â”‚
â”‚   â”‚    m_t = Î²â‚Â·m_{t-1}     â”‚                                â”‚
â”‚   â”‚         + (1-Î²â‚)Â·gÌƒ_t    â”‚                                â”‚
â”‚   â”‚    v_t = Î²â‚‚Â·v_{t-1}     â”‚                                â”‚
â”‚   â”‚         + (1-Î²â‚‚)Â·gÌƒ_tÂ²   â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 7. Parameter Update     â”‚                                â”‚
â”‚   â”‚    p_{t+1} = p_t        â”‚                                â”‚
â”‚   â”‚         - Î± Â· mÌ‚_t/âˆšvÌ‚_t â”‚  (Adam-style)                  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚           Output: Updated parameters                          â”‚
â”‚                                                                â”‚
â”‚   Key Properties:                                             â”‚
â”‚   â€¢ Prevents catastrophic forgetting (utility protection)    â”‚
â”‚   â€¢ Maintains plasticity (noise injection)                   â”‚
â”‚   â€¢ Adaptive learning rates (AdaptiveUPGD)                   â”‚
â”‚   â€¢ Compatible with VGS (reduce Ïƒ to 0.001)                  â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation**: [optimizers/upgd_optimizer.py](optimizers/upgd_optimizer.py)

**Documentation**: [docs/UPGD_INTEGRATION.md](docs/UPGD_INTEGRATION.md)

**Tests**: `tests/test_upgd*.py`

---

## ğŸ†• VGS (Variance Gradient Scaler) Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Variance Gradient Scaler (VGS)                    â”‚
â”‚           Automatic Per-Layer Gradient Scaling                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚   Training Loop:                                              â”‚
â”‚                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 1. Accumulation Phase   â”‚                                â”‚
â”‚   â”‚    (N backward passes)  â”‚  N=4 (default)                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ For each layer:         â”‚                                â”‚
â”‚   â”‚   gradients[i].append(  â”‚                                â”‚
â”‚   â”‚     layer.grad.clone()  â”‚                                â”‚
â”‚   â”‚   )                     â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 2. Compute Variance     â”‚                                â”‚
â”‚   â”‚    Ïƒ_i = std(grads[i])  â”‚  Per-layer std                 â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 3. Compute Scale        â”‚                                â”‚
â”‚   â”‚    s_i = 1/(Ïƒ_i + Îµ)    â”‚  Îµ=1e-6 for stability          â”‚
â”‚   â”‚    s_i = clip(s_i,      â”‚  clip to [1/thresh, thresh]    â”‚
â”‚   â”‚              max=10.0)  â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 4. Apply Scaling        â”‚                                â”‚
â”‚   â”‚    layer.grad *= s_i    â”‚  Scale gradients               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 5. Optimizer Step       â”‚                                â”‚
â”‚   â”‚    optimizer.step()     â”‚  (AdaptiveUPGD or other)       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 6. Clear Accumulator    â”‚                                â”‚
â”‚   â”‚    gradients.clear()    â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                                                â”‚
â”‚   Integration with UPGD:                                      â”‚
â”‚   â€¢ VGS scales gradients BEFORE UPGD noise injection         â”‚
â”‚   â€¢ Reduce UPGD Ïƒ to 0.001 to prevent amplification          â”‚
â”‚   â€¢ State dict compatibility for PBT checkpointing           â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation**: [variance_gradient_scaler.py](variance_gradient_scaler.py)

**Integration**: [distributional_ppo.py](distributional_ppo.py) (VGS integration)

**Tests**: `tests/test_upgd_vgs*.py`

---

## ğŸ†• Twin Critics Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Twin Critics Architecture                   â”‚
â”‚             (Reduce Overestimation Bias in Value)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚   Input: Observation (56D)                                    â”‚
â”‚      â”‚                                                         â”‚
â”‚      â–¼                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚  Shared Feature Encoder â”‚                                â”‚
â”‚   â”‚  (LSTM + MLP)           â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                          â”‚
â”‚         â–¼          â–¼                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ Critic 1 â”‚  â”‚ Critic 2 â”‚  (Independent heads)            â”‚
â”‚   â”‚ Head     â”‚  â”‚ Head     â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                â”‚
â”‚        â”‚              â”‚                                       â”‚
â”‚        â–¼              â–¼                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ Value 1  â”‚  â”‚ Value 2  â”‚  (Distributional: 21-51 atoms) â”‚
â”‚   â”‚ (Q-dist) â”‚  â”‚ (Q-dist) â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                â”‚
â”‚        â”‚              â”‚                                       â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â”‚               â–¼                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ Min Operator            â”‚                                â”‚
â”‚   â”‚ V_target = min(V1, V2)  â”‚  (Reduce overestimation)       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   Target Value for Policy Update                             â”‚
â”‚                                                                â”‚
â”‚   Training:                                                   â”‚
â”‚   â€¢ Both critics updated with same target                    â”‚
â”‚   â€¢ Quantile regression loss (Huber)                         â”‚
â”‚   â€¢ CVaR regularization (worst 5% tail)                      â”‚
â”‚                                                                â”‚
â”‚   Benefits:                                                   â”‚
â”‚   â€¢ Reduced overestimation bias                              â”‚
â”‚   â€¢ Improved stability in stochastic environments            â”‚
â”‚   â€¢ Better convergence for distributional RL                 â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation**: [distributional_ppo.py](distributional_ppo.py) (Twin Critics integration)

**Documentation**: [docs/twin_critics.md](docs/twin_critics.md)

**Tests**: `tests/test_twin_critics*.py`

**Research**:
- Fujimoto et al. (2018) "Addressing Function Approximation Error in Actor-Critic Methods"
- PDPPO (2025) - recent distributional PPO with twin critics

---

## ğŸ†• PBT (Population-Based Training) Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Population-Based Training (PBT) Flow                 â”‚
â”‚          Evolutionary Hyperparameter Optimization              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚   Initialize Population (N=8 agents):                         â”‚
â”‚                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚ A1  â”‚ â”‚ A2  â”‚ â”‚ A3  â”‚ â”‚ A4  â”‚ â”‚ A5  â”‚ â”‚ A6  â”‚ â”‚ A7  â”‚ â”‚
â”‚   â”‚lr1  â”‚ â”‚lr2  â”‚ â”‚lr3  â”‚ â”‚lr4  â”‚ â”‚lr5  â”‚ â”‚lr6  â”‚ â”‚lr7  â”‚ â”‚
â”‚   â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â”‚
â”‚      â”‚       â”‚       â”‚       â”‚       â”‚       â”‚       â”‚      â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                            â”‚                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚  Training Phase (10 steps)                      â”‚       â”‚
â”‚   â”‚  Each agent trains independently                â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                            â”‚                                  â”‚
â”‚                            â–¼                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚  Evaluation Phase                               â”‚       â”‚
â”‚   â”‚  Measure performance (mean_reward)              â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                            â”‚                                  â”‚
â”‚                            â–¼                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚  Exploit Phase                                  â”‚       â”‚
â”‚   â”‚  Sort by performance: A7 > A3 > A1 > ... > A5  â”‚       â”‚
â”‚   â”‚  Truncation selection (top 25% vs bottom 25%)   â”‚       â”‚
â”‚   â”‚                                                 â”‚       â”‚
â”‚   â”‚  Bottom agents copy weights from top agents:   â”‚       â”‚
â”‚   â”‚    A5.weights â† A7.weights                     â”‚       â”‚
â”‚   â”‚    A2.weights â† A3.weights                     â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                            â”‚                                  â”‚
â”‚                            â–¼                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚  Explore Phase                                  â”‚       â”‚
â”‚   â”‚  Perturb hyperparameters (Ã—1.2 or Ã·1.2):       â”‚       â”‚
â”‚   â”‚    lr_new = lr_old Ã— 1.2  (or Ã·1.2)            â”‚       â”‚
â”‚   â”‚                                                 â”‚       â”‚
â”‚   â”‚  OR Resample from uniform distribution:        â”‚       â”‚
â”‚   â”‚    lr_new ~ Uniform[lr_min, lr_max]            â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                            â”‚                                  â”‚
â”‚                            â–¼                                  â”‚
â”‚   Repeat (Training â†’ Eval â†’ Exploit â†’ Explore)              â”‚
â”‚                                                                â”‚
â”‚   Hyperparameters optimized:                                 â”‚
â”‚   â€¢ learning_rate                                            â”‚
â”‚   â€¢ adversarial_epsilon (for SA-PPO)                         â”‚
â”‚   â€¢ clip_range                                               â”‚
â”‚   â€¢ ent_coef                                                 â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation**: [adversarial/pbt_scheduler.py](adversarial/pbt_scheduler.py)

**Integration**: [training_pbt_adversarial_integration.py](training_pbt_adversarial_integration.py)

**Config**: [configs/config_pbt_adversarial.yaml](configs/config_pbt_adversarial.yaml)

**Tests**: `tests/test_pbt*.py`

**Research**: Jaderberg et al. (2017) "Population Based Training of Neural Networks"

---

## ğŸ”´ Critical Fixes Architecture (2025-11-21)

### LSTM Episode Boundary Reset

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          LSTM State Management (CRITICAL FIX)                  â”‚
â”‚        Prevent Temporal Leakage Between Episodes               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚   Rollout Loop:                                               â”‚
â”‚                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 1. Collect Experience   â”‚                                â”‚
â”‚   â”‚    obs, actions, ...    â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 2. Environment Step     â”‚                                â”‚
â”‚   â”‚    obs', reward, done   â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 3. Check done flags     â”‚                                â”‚
â”‚   â”‚    IF any done == True  â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚         YES  â”‚  NO                                            â”‚
â”‚         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                                           â”‚
â”‚         â–¼         â–¼                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Continue                                     â”‚
â”‚   â”‚ 4. RESET â”‚                                               â”‚
â”‚   â”‚ LSTM     â”‚  âš ï¸ NEW (2025-11-21)                          â”‚
â”‚   â”‚ states   â”‚                                               â”‚
â”‚   â”‚          â”‚  Method:                                      â”‚
â”‚   â”‚ self._last_lstm_states =                                â”‚
â”‚   â”‚   _reset_lstm_states_for_done_envs(                     â”‚
â”‚   â”‚     lstm_states=self._last_lstm_states,                 â”‚
â”‚   â”‚     episode_starts=episode_starts                       â”‚
â”‚   â”‚   )                                                      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ 5. Continue Rollout     â”‚                                â”‚
â”‚   â”‚    Clean LSTM state     â”‚                                â”‚
â”‚   â”‚    No temporal leakage  â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                                                â”‚
â”‚   Impact:                                                     â”‚
â”‚   â€¢ Prevents information flow between unrelated episodes     â”‚
â”‚   â€¢ Improves value estimation accuracy (5-15%)               â”‚
â”‚   â€¢ Critical for recurrent policies                          â”‚
â”‚                                                                â”‚
â”‚   Location: distributional_ppo.py:7418-7427                  â”‚
â”‚   Tests: tests/test_lstm_episode_boundary_reset.py (8 tests) â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Documentation**: [CRITICAL_LSTM_RESET_FIX_REPORT.md](CRITICAL_LSTM_RESET_FIX_REPORT.md)

**Tests**: [tests/test_lstm_episode_boundary_reset.py](tests/test_lstm_episode_boundary_reset.py)

**Research**: Hausknecht & Stone (2015) "Deep Recurrent Q-Learning for Partially Observable MDPs"

---

### Action Space Semantics Fix

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Action Space Semantics (CRITICAL FIX)                â”‚
â”‚          DELTA â†’ TARGET Position Semantics                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚   OLD (DELTA - WRONG):                                        â”‚
â”‚                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ Current position: 1000  â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ Action: +0.5            â”‚  (increase by 50%)             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ âŒ DELTA Interpretation â”‚                                â”‚
â”‚   â”‚ new = cur + (0.5*max)   â”‚                                â”‚
â”‚   â”‚ new = 1000 + 500        â”‚                                â”‚
â”‚   â”‚ new = 1500              â”‚  Position DOUBLED!             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                                                â”‚
â”‚   NEW (TARGET - CORRECT):                                     â”‚
â”‚                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ Current position: 1000  â”‚                                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ Action: +0.5            â”‚  (target 50% of max)           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚              â”‚                                                 â”‚
â”‚              â–¼                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚   â”‚ âœ… TARGET Interpretationâ”‚                                â”‚
â”‚   â”‚ new = 0.5 * max         â”‚                                â”‚
â”‚   â”‚ new = 500               â”‚  Correct target position       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                                                â”‚
â”‚   Impact:                                                     â”‚
â”‚   â€¢ Prevents position doubling bug                           â”‚
â”‚   â€¢ Prevents 2x leverage violation in production             â”‚
â”‚   â€¢ Models with DELTA semantics MUST retrain                 â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Documentation**: [CRITICAL_FIXES_COMPLETE_REPORT.md](CRITICAL_FIXES_COMPLETE_REPORT.md)

**Tests**: [tests/test_critical_action_space_fixes.py](tests/test_critical_action_space_fixes.py)

---

## References

### Academic Papers
- **UPGD**: Farahmand et al. (2017) "Utility-based Perturbed Gradient Descent"
- **Twin Critics**: Fujimoto et al. (2018) "Addressing Function Approximation Error in Actor-Critic Methods"
- **PBT**: Jaderberg et al. (2017) "Population Based Training of Neural Networks"
- **LSTM in RL**: Hausknecht & Stone (2015) "Deep Recurrent Q-Learning for Partially Observable MDPs"
- **Distributional RL**: Dabney et al. (2018) "Distributional Reinforcement Learning with Quantile Regression"

### Project Documentation
- [docs/UPGD_INTEGRATION.md](docs/UPGD_INTEGRATION.md)
- [docs/twin_critics.md](docs/twin_critics.md)
- [CRITICAL_LSTM_RESET_FIX_REPORT.md](CRITICAL_LSTM_RESET_FIX_REPORT.md)
- [CRITICAL_FIXES_COMPLETE_REPORT.md](CRITICAL_FIXES_COMPLETE_REPORT.md)
- [NUMERICAL_ISSUES_FIX_SUMMARY.md](NUMERICAL_ISSUES_FIX_SUMMARY.md)
- [REGRESSION_PREVENTION_CHECKLIST.md](REGRESSION_PREVENTION_CHECKLIST.md)

---

**Maintained by**: Development Team + Claude Code
**Last Updated**: 2025-11-21
**Version**: 2.1
